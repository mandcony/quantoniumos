# QuantoniumOS Technical Summary (Validated September 2025)

This document captures the current, evidence-based status of QuantoniumOS. Claims from earlier revisions that are not backed by a fresh test run are removed or explicitly marked as *unverified*.

## Verified components

| Area | Module(s) | Validation | Outcome |
| --- | --- | --- | --- |
| Tensor codec | `src/core/rft_vertex_codec.py` | `pytest tests/tests/test_rft_vertex_codec.py` | Lossless round-trips succeed for float/int/bool tensors; lossy mode respects the ≤0.2 max-error guardrail; checksum fallback works as designed. |
| Compressed model routing | `src/apps/compressed_model_router.py`, `src/core/rft_hybrid_codec.py` | `pytest tests/apps/test_compressed_model_router.py` | Discovers decoded/encoded manifests, instantiates stub HuggingFace models, and rebuilds tensors produced by the hybrid codec. |

These tests ran on Python 3.12.1 inside the project’s dev container (Ubuntu 24.04). Warnings during the codecs run indicate automatic fallbacks to raw payloads when ANS quantization thresholds are too aggressive—this is expected behaviour and is covered by assertions.

## Experimental subsystems (not revalidated)

The repository contains broader research code that was **not** executed in this pass. Use it with caution and re-document your own findings:

- **Vertex/entanglement engine** (`src/engine/`), including Bell-test tooling under `tests/proofs/`, requires QuTiP and additional numerical checks. All claims of Bell inequality violations or Schmidt-rank guarantees remain unverified here.
- **Large-scale benchmarks** stored in `results/` (e.g., “million-vertex” or “BULLETPROOF” datasets) reflect historical runs. Re-run the scripts in `tests/analysis/` or `tests/tests/` before citing them.
- **Cryptographic suite** (`src/core/enhanced_rft_crypto_v2.py`, `tests/crypto/`) was not executed. Treat avalanche/DP/LP metrics as prior results until reproduced.
- **Assembly kernels** under `src/assembly/` were not rebuilt; all tests used the pure-Python fallback logic.

## Architectural snapshot

```
src/
├── apps/                # PyQt5 apps, compression utilities, model router
├── assembly/            # Optional AVX/SIMD kernels + bindings (off by default)
├── core/                # RFT codecs, hybrid codec, math helpers, crypto
├── engine/              # Experimental vertex/entanglement implementations
└── frontend/            # Desktop shell and widgets
```

Supporting directories `ai/`, `encoded_models/`, and `decoded_models/` contain the example model assets documented in `FINAL_AI_MODEL_INVENTORY.md`. Historical mentions of additional GPT-Neo or Phi-3 archives do not correspond to files in this snapshot.

### Current model & codec snapshot

| Asset | Location | Verification | Note |
| --- | --- | --- | --- |
| GPT‑OSS quantum sample | `ai/models/quantum/quantonium_120b_quantum_states.json` | `python - <<'PY'` ... `json.load(...)` → 4 096 states, metadata claims 120 B original / 351.9 M effective parameters. | 2.3 MB symbolic JSON generated by `tools/generate_gpt_oss_quantum_sample.py`. |
| Tiny GPT‑2 RFT bundle | `encoded_models/tiny_gpt2_lossless/` | Manifest metrics show ≈2.9 MB original → ≈29 MB encoded, lossless. | 33 tensors + manifest for `sshleifer/tiny-gpt2`. |
| Tiny GPT‑2 decoded weights | `decoded_models/tiny_gpt2_lossless/state_dict.pt` | `torch.load(...); sum(t.numel())` → 2 300 382 parameters. | PyTorch checkpoint reconstructed from the encoded bundle. |

The orphaned DistilGPT‑2 chunk that previously lived under `encoded_models/distilgpt2_lossless/` was deleted during this review to avoid shipping unverifiable data. Regenerate the bundle from the original weights if you require that checkpoint.

## How to reproduce the verified results

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
pytest tests/tests/test_rft_vertex_codec.py
pytest tests/apps/test_compressed_model_router.py
```

Expected runtime is under 15 seconds on a commodity CPU. Both modules should report 100% pass with runtime warnings noted above.

## Guidance for further validation

- **Desktop shell**: Launch `python quantonium_boot.py` after installing PyQt5 to confirm UI wiring. Document any issues in `docs/`.
- **Entanglement experiments**: Install QuTiP, then run `python tests/proofs/test_entanglement_protocols.py` or its helper functions. Update this file with the success rate and hardware specs if you reproduce Bell inequality violations.
- **Benchmark scripts**: The analytics scripts in `tests/analysis/` and `tests/tests/` include CLI entry points. Run them selectively, capture logs in `results/`, and amend both this summary and the README with fresh measurements.
- **Cryptography**: Execute `pytest tests/crypto` (may require additional dependencies) to check avalanche/key-schedule behaviour; cite metrics and sample sizes explicitly.
- **Native diagnostics**: Build the kernels with `make asan` in `src/assembly/` when you need AddressSanitizer coverage before rerunning the hybrid/quantum pytest modules.

## Known gaps and caveats

- Only the modules documented under **Verified components** have recent pytest evidence. Any other subsystem should be treated as unverified until you capture fresh test output or analytical proofs.
- Symbolic “qubit” counts are derived from graph vertex encodings—do not equate them with physical qubits.
- Performance claims depend heavily on data sparsity; worst-case inputs revert to raw storage formats and lose compression benefits.
- Optional assemblies are wrapper-dependent; without compilation, performance matches pure Python.
- Documentation that still references “production”, “genuine entanglement”, or similar terminology should be read as aspirational until re-tested.

## Next documentation checkpoint

When new validations are completed, include:

1. Command(s) executed and commit hash.
2. Hardware/environment summary.
3. Raw metrics or artefact paths.
4. Updates to both this summary and the top-level README.

Keeping these records current ensures that statements about QuantoniumOS remain tied to reproducible evidence.
