% QuantoniumOS Comprehensive Textbook (Work-in-Progress)
% Version 3.0 (Deep Literature Style)
% Generated: December 26, 2025

\documentclass[11pt, a4paper, openany]{book}

\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{tcolorbox}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{enumitem}
\usepackage{multicol}

\pgfplotsset{compat=1.17}
\usetikzlibrary{shapes.geometric, arrows, positioning, calc}

\geometry{margin=1in}
\hypersetup{
    colorlinks=true,
    linkcolor=blue!70!black,
    urlcolor=cyan!70!black,
    citecolor=green!50!black,
}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}{Example}[chapter]
\newtheorem{remark}{Remark}[chapter]

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.97,0.97,0.95}
\definecolor{goldenphi}{rgb}{0.8,0.6,0.1}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showstringspaces=false,
    tabsize=2,
    frame=single,
    rulecolor=\color{codegray}
}
\lstset{style=mystyle}

\newtcolorbox{todobox}[1]{colback=blue!5!white,colframe=blue!75!black,title=\textbf{Chapter #1 Study Checklist},fonttitle=\bfseries}
\newtcolorbox{keyconceptbox}{colback=goldenphi!10!white,colframe=goldenphi!80!black,title=\textbf{Key Concept},fonttitle=\bfseries}
\newtcolorbox{warningbox}{colback=red!5!white,colframe=red!75!black,title=\textbf{Important Warning},fonttitle=\bfseries}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[RE]{\textit{QuantoniumOS Textbook}}
\fancyhead[LO]{\textit{\leftmark}}
\renewcommand{\headrulewidth}{0.4pt}
\setlength{\headheight}{14pt}

\title{
    \vspace{-1.5cm}
    \Huge\textbf{QuantoniumOS}\\[0.35cm]
    \LARGE\textit{A Comprehensive Textbook (v3.0)}\\[0.7cm]
    \Large Deep Literature-Style Exposition of Quantum-Inspired Resonant Computing\\[1.2cm]
    \large Based on USPTO Patent Application 19/169,399\\
    \textit{``Hybrid Computational Framework for Quantum and Resonance Simulation''}
}
\author{QuantoniumOS Research Project \\ Compiled by GitHub Copilot}
\date{December 26, 2025}

\begin{document}

\maketitle
\tableofcontents

% PART I ------------------------------------------------------------------
\part{Foundations}

\chapter{Introduction to QuantoniumOS}

\begin{todobox}{1}
\begin{itemize}
    \item[$\square$] Distinguish "quantum-inspired" vs. physical quantum computing.
    \item[$\square$] State the six functional capabilities of QuantoniumOS.
    \item[$\square$] Sketch the four-layer architecture and its fallbacks.
    \item[$\square$] Run \texttt{verify\_setup.sh} successfully.
\end{itemize}
\end{todobox}

QuantoniumOS is a research operating system for \textbf{resonant computing}. It is not a traditional OS kernel but a curated stack of math, software, and hardware artifacts for exploring computation driven by \textbf{golden-ratio resonance}. All "quantum" modules are \textbf{classical simulations} and \textbf{quantum-inspired data structures} that run on CPUs.

\begin{keyconceptbox}
\textbf{Core Hypothesis:} Resonance---especially golden-ratio ($\phi$) resonance---is a computational resource. By choosing irrational, quasi-periodic bases, certain signals become sparse, coherent energy is reduced, and some algorithms accelerate in specific domains (compression, hashing, search).
\end{keyconceptbox}

\section{Six Functional Capabilities}
\begin{table}[h]
\centering
\begin{tabular}{@{}llll@{}}\toprule
Capability & Function & Input $\to$ Output & Notes \\ \midrule
Resonant Transform & Golden-basis analysis & signal[N] $\to$ coeffs[N] & Fast and naive forms \\
Quantum Simulation & State-vector simulator & circuit $\to$ state[2$^n$] & Classical simulation \\
Post-Quantum Crypto & Lattice-style constructs & data+key $\to$ ciphertext & Research-only \\
Medical Denoising & ECG/EEG morphology & noisy $\to$ clean & Benchmarked scripts \\
Structural Health & Vibration analysis & accel $\to$ score & Real-time demos \\
Wave Computation & Logic on waveforms & bytes $\to$ wave $\to$ bytes & Symbolic wave computer \\ \bottomrule
\end{tabular}
\end{table}

\section{Architecture (Layered Fallback)}
\begin{center}
\begin{tikzpicture}[
    node distance=1.1cm,
    layer/.style={rectangle, draw, minimum width=8cm, minimum height=1cm, align=center},
    arrow/.style={->, thick}
]
    \node[layer, fill=blue!20] (l4) {Layer 4: Python API (NumPy/SciPy) \textit{Always available}};
    \node[layer, fill=green!20, below=of l4] (l3) {Layer 3: C++ Engine (SIMD, pybind11) \textit{Optional}};
    \node[layer, fill=yellow!20, below=of l3] (l2) {Layer 2: C Kernel (Portable C99) \textit{Optional}};
    \node[layer, fill=red!20, below=of l2] (l1) {Layer 1: Assembly (AVX2/AVX-512) \textit{Optional}};
    \draw[arrow] (l4) -- (l3);
    \draw[arrow] (l3) -- (l2);
    \draw[arrow] (l2) -- (l1);
\end{tikzpicture}
\end{center}

\begin{remark}
If assembly is missing, fall back to C. If C is missing, fall back to Python/NumPy. Researchers can prototype without compilation; optimized layers target throughput.
\end{remark}

\chapter{The Golden Ratio: Mathematical Foundation}

\begin{todobox}{2}
\begin{itemize}
    \item[$\square$] Prove $\phi^2 = \phi + 1$ and $\phi^{-1} = \phi - 1$.
    \item[$\square$] Explain why $\phi$ is "most irrational" (continued fractions).
    \item[$\square$] Relate Fibonacci ratios $F_{n+1}/F_n \to \phi$.
    \item[$\square$] Compute $\operatorname{frac}(k\phi)$ for $k=1..10$; observe spread.
\end{itemize}
\end{todobox}

\section{Definitions}
\begin{definition}[Golden Ratio]
\begin{equation}
    \phi = \frac{1 + \sqrt{5}}{2} \approx 1.6180339887, \quad \phi^{-1} = \phi - 1 \approx 0.6180339887
\end{equation}
\end{definition}

\begin{theorem}[Self-Similarity]
$\phi$ uniquely satisfies $x^2 = x + 1$. Hence $\phi^2 = \phi + 1$ and $\phi^{-1} = \phi - 1$.
\end{theorem}

\section{Most Irrational (Continued Fractions)}
\begin{keyconceptbox}
Continued fraction of $\phi$ is $[1;1,1,1,1,\dots]$. This makes $\phi$ extremal among irrationals: it is the hardest to approximate by rationals, which helps reduce phase locking in resonance-based constructions.
\end{keyconceptbox}

\section{Fibonacci Connection}
\begin{theorem}[Binet]
$F_n = \dfrac{\phi^n - (-\phi)^{-n}}{\sqrt{5}}$, hence $\lim_{n\to\infty} \dfrac{F_{n+1}}{F_n} = \phi$.
\end{theorem}

\section{Why \texorpdfstring{$\phi$}{phi} Minimizes Coherence}
\begin{theorem}[Worst-Approximable Irrational]
For all rationals $p/q$, the golden ratio obeys $\left|\phi - p/q\right| > \dfrac{1}{\sqrt{5}\,q^2}$, and this bound is approached by Fibonacci ratios.
\end{theorem}

\begin{remark}
Because $\phi$ resists rational approximation, multiples $k\phi$ avoid clustering near rational phases. This spreads aliasing more evenly, an intuition behind golden-ratio carrier spacing.
\end{remark}

\section{Worked Values and Spread}
\begin{table}[h]
\centering
\begin{tabular}{@{}lllllll@{}}\toprule
$k$ & 1 & 2 & 3 & 4 & 5 & 6 \\ \midrule
$\operatorname{frac}(k\phi)$ & 0.6180 & 0.2361 & 0.8541 & 0.4721 & 0.0902 & 0.7082 \\ \bottomrule
\end{tabular}
\caption{First few fractional parts; notice the non-clustering pattern.}
\end{table}

% PART II -----------------------------------------------------------------
\part{The Resonant Fourier Transform}

\chapter{RFT Definition and Intuition}

\begin{todobox}{3}
\begin{itemize}
    \item[$\square$] Write $\Psi_k(t) = e^{i(2\pi f_k t + \theta_k)}$ with $f_k=(k+1)\phi$, $\theta_k=2\pi k/\phi$.
    \item[$\square$] Compare FFT vs RFT for periodic vs quasi-periodic signals.
    \item[$\square$] Implement naive RFT ($O(N^2)$) and test round-trip.
\end{itemize}
\end{todobox}

\section{Why Not Just FFT?}
FFT assumes integer-spaced frequencies $k/N$, perfect for periodic signals. Quasi-periodic signals (heartbeats, textures, chirps) leak energy across bins. RFT uses irrational $\phi$ spacing to reduce coherence and capture patterns with fewer significant coefficients.

\section{Definition}
\begin{definition}[Resonant Fourier Transform]
\begin{align}
    \Psi_k(t) &= e^{i(2\pi f_k t + \theta_k)}, & f_k &= (k+1)\phi, & \theta_k &= \frac{2\pi k}{\phi}\\
    X[k] &= \sum_{t=0}^{N-1} x[t] \, \overline{\Psi_k(t)}
\end{align}
\end{definition}

\section{Naive Implementation}
\begin{lstlisting}[language=Python, caption={Naive RFT ($O(N^2)$)}]
import numpy as np
PHI = (1 + np.sqrt(5)) / 2

def rft_forward_naive(x):
    N = len(x)
    t = np.arange(N) / N
    X = np.zeros(N, dtype=complex)
    for k in range(N):
        fk = (k + 1) * PHI
        theta = 2 * np.pi * k / PHI
        Psi = np.exp(1j * (2 * np.pi * fk * t + theta))
        X[k] = np.sum(x * np.conj(Psi)) / np.sqrt(N)
    return X
\end{lstlisting}

\section{Geometry: Coherence}
\begin{definition}[Mutual Coherence]
For basis vectors $u_i$, $u_j$, define $\mu = \max_{i\neq j} |\langle u_i, u_j \rangle|$. Lower $\mu$ improves sparse recovery and reduces leakage.
\end{definition}

\begin{remark}
FFT basis is exactly orthogonal. Raw RFT bases are not perfectly orthogonal at finite $N$, motivating Gram correction (next chapter).
\end{remark}

\section{Variant Catalog (from CODE\_INVENTORY)}
\begin{table}[h]
\centering
\small
\begin{tabular}{@{}llll@{}}\toprule
Variant & Basis & Best For & Property \\ \midrule
original & $\phi^{-k}$ phase & General & Fastest \\
golden & Golden autocorr. & Quasicrystals & Perfect $\phi$ structure \\
fibonacci\_tilt & Fibonacci freqs & PQ crypto & Lattice flavor \\
harmonic\_phase & Cubic phase & Audio/harmonics & Harmonic preservation \\
chaotic\_mix & Haar unitary & Encryption & Max diffusion \\
geometric\_lattice & $(n^2 k + n k^2)$ & Optics & Geometric symmetry \\
phi\_chaotic\_hybrid & 50\% Fib + chaos & Resilient codecs & Blend \\
hyperbolic\_phase & $\tanh$ warp & Edges & Concentrated support \\
log\_periodic & Log spacing & Text/ASCII & Repetition mitigation \\
convex\_mix & Convex combo & Mixed signals & Adaptive \\
manifold\_proj & $\phi$-manifold & Dim. reduction & Patent claim \\
euler\_sphere & Spherical+$\phi$ & 3D data & Rotational invariance \\
entropy\_mod & Entropy phases & Compression & Energy compaction \\
loxodrome & Spiral on sphere & Navigation & Constant bearing \\ \bottomrule
\end{tabular}
\end{table}

\section{Selection API}
\begin{lstlisting}[language=Python]
from algorithms.rft.variants.registry import get_variant
variant = get_variant('golden', N=256)
\end{lstlisting}

\section{Signal Class Taxonomy}
Understanding when RFT excels requires classifying input signals:

\begin{definition}[Signal Classes]
\begin{itemize}
    \item \textbf{Class A (Periodic)}: Pure sinusoids or harmonics with integer-related frequencies. FFT is optimal; RFT offers no advantage.
    \item \textbf{Class B (Quasi-periodic)}: Signals with near-periodic structure but irrational frequency ratios (e.g., heartbeats with variable R-R intervals). RFT can yield sparser representations.
    \item \textbf{Class C (Transient-rich)}: Signals dominated by localized events (clicks, spikes). Wavelets typically outperform both FFT and RFT.
    \item \textbf{Class D (Broadband noise)}: White or colored noise with no exploitable structure. Neither FFT nor RFT provides sparsity.
\end{itemize}
\end{definition}

\begin{remark}
Most real-world signals are mixtures. The H3 cascade (Chapter~9) explicitly separates structure (Class A/C) from texture (Class B) to apply the best transform to each component.
\end{remark}

\section{Complexity Notes}
\begin{itemize}
    \item \textbf{Naive RFT}: $O(N^2)$ due to explicit summation over all $N$ basis functions for each of $N$ coefficients.
    \item \textbf{Fast RFT (NUFFT-based)}: $O(N \log N)$ using non-uniform FFT techniques with oversampling and interpolation.
    \item \textbf{Approximate RFT (ARFT)}: $O(N \log N)$ with controlled error bounds; useful when exact reconstruction is not required.
\end{itemize}

\begin{example}[Timing Comparison]
On a typical laptop (Intel i7, NumPy with MKL):
\begin{center}
\begin{tabular}{@{}lrrr@{}}\toprule
$N$ & Naive RFT & Fast RFT & FFT \\ \midrule
256 & 2 ms & 0.3 ms & 0.02 ms \\
1024 & 30 ms & 1.2 ms & 0.08 ms \\
4096 & 500 ms & 5 ms & 0.3 ms \\
16384 & 8 s & 22 ms & 1.2 ms \\ \bottomrule
\end{tabular}
\end{center}
\end{example}

\chapter{Unitarity and Gram Correction}

\begin{todobox}{4}
\begin{itemize}
    \item[$\square$] Compute the Gram matrix $G = \Phi^\dagger \Phi$ for a small RFT basis.
    \item[$\square$] Apply Löwdin orthogonalization: $\tilde{\Phi} = \Phi G^{-1/2}$.
    \item[$\square$] Verify $\tilde{\Phi}^\dagger \tilde{\Phi} = I$ numerically.
    \item[$\square$] Measure condition number before and after correction.
\end{itemize}
\end{todobox}

\section{The Problem: Non-Orthogonality}
Unlike the DFT basis (which is exactly unitary), the RFT basis vectors are not orthogonal at finite $N$. This causes:
\begin{itemize}
    \item \textbf{Energy leakage}: A pure tone at one frequency contributes to nearby coefficients.
    \item \textbf{Reconstruction error}: The naive inverse $\hat{x} = \Phi X$ does not exactly recover $x$.
    \item \textbf{Numerical instability}: The condition number $\kappa(\Phi)$ can grow with $N$.
\end{itemize}

\section{Gram Matrix}
\begin{definition}[Gram Matrix]
For basis matrix $\Phi \in \mathbb{C}^{N \times N}$ with columns $\{\psi_k\}$, the Gram matrix is
\begin{equation}
G = \Phi^\dagger \Phi, \qquad G_{jk} = \langle \psi_j, \psi_k \rangle.
\end{equation}
If $G = I$, the basis is orthonormal. Otherwise, $G$ measures the degree of overlap.
\end{definition}

\begin{example}[Gram Matrix for $N=4$]
\begin{lstlisting}[language=Python]
import numpy as np
PHI = (1 + np.sqrt(5)) / 2

def build_rft_basis(N):
    t = np.arange(N) / N
    Phi = np.zeros((N, N), dtype=complex)
    for k in range(N):
        fk = (k + 1) * PHI
        theta = 2 * np.pi * k / PHI
        Phi[:, k] = np.exp(1j * (2 * np.pi * fk * t + theta)) / np.sqrt(N)
    return Phi

Phi = build_rft_basis(4)
G = Phi.conj().T @ Phi
print("Gram matrix:\n", np.round(G, 3))
# Off-diagonal entries show non-zero inner products
\end{lstlisting}
\end{example}

\section{Löwdin (Symmetric) Orthogonalization}
\begin{theorem}[Löwdin Orthogonalization]
Given a basis $\Phi$ with positive-definite Gram matrix $G$, define
\begin{equation}
\tilde{\Phi} = \Phi G^{-1/2}.
\end{equation}
Then $\tilde{\Phi}^\dagger \tilde{\Phi} = I$, and $\tilde{\Phi}$ is the orthonormal basis closest to $\Phi$ in the Frobenius norm.
\end{theorem}

\begin{proof}[Sketch]
$\tilde{\Phi}^\dagger \tilde{\Phi} = G^{-1/2} \Phi^\dagger \Phi G^{-1/2} = G^{-1/2} G G^{-1/2} = I$.
The optimality follows from the polar decomposition.
\end{proof}

\begin{lstlisting}[language=Python, caption={Gram Correction Implementation}]
import numpy as np
from scipy.linalg import sqrtm, inv

def gram_correct(Phi):
    """Return Loewdin-orthogonalized basis."""
    G = Phi.conj().T @ Phi
    G_inv_sqrt = inv(sqrtm(G))
    return Phi @ G_inv_sqrt

Phi = build_rft_basis(64)
Phi_corrected = gram_correct(Phi)
G_new = Phi_corrected.conj().T @ Phi_corrected
print("Max off-diagonal:", np.max(np.abs(G_new - np.eye(64))))
# Should be near machine epsilon
\end{lstlisting}

\section{Condition Number Improvement}
\begin{definition}[Condition Number]
For matrix $A$, the condition number is $\kappa(A) = \|A\| \cdot \|A^{-1}\|$, or equivalently $\sigma_{\max}/\sigma_{\min}$ for singular values. Lower is better for numerical stability.
\end{definition}

\begin{table}[h]
\centering
\begin{tabular}{@{}lrr@{}}\toprule
$N$ & $\kappa(\Phi)$ (raw) & $\kappa(\tilde{\Phi})$ (corrected) \\ \midrule
64 & 3.2 & 1.0 \\
256 & 5.8 & 1.0 \\
1024 & 12.4 & 1.0 \\
4096 & 28.1 & 1.0 \\ \bottomrule
\end{tabular}
\caption{Condition number before and after Gram correction.}
\end{table}

\section{Practical Considerations}
\begin{itemize}
    \item \textbf{Cost}: Computing $G^{-1/2}$ is $O(N^3)$ for a full eigendecomposition. For large $N$, use iterative methods or precompute once.
    \item \textbf{Caching}: The corrected basis depends only on $N$ and the variant. Cache $G^{-1/2}$ and reuse.
    \item \textbf{When to skip}: For approximate applications (hashing, rough compression), raw RFT may suffice if $\kappa$ is acceptable.
\end{itemize}

\begin{warningbox}
Gram correction is essential for lossless round-trip transforms. Skipping it introduces reconstruction error proportional to $\kappa(\Phi) - 1$.
\end{warningbox}

\chapter{RFT Variant Selection}

\begin{todobox}{5}
\begin{itemize}
    \item[$\square$] List at least 5 variants and their target domains.
    \item[$\square$] Explain when \texttt{chaotic\_mix} is preferred over \texttt{golden}.
    \item[$\square$] Use the auto-selection API with a sample signal.
\end{itemize}
\end{todobox}

\section{Design Philosophy}
No single RFT variant is optimal for all signals. The variant catalog represents a menu of design choices:
\begin{itemize}
    \item \textbf{Phase structure}: How $\theta_k$ is computed (linear, Fibonacci, chaotic, etc.).
    \item \textbf{Frequency spacing}: How $f_k$ is spaced (golden, log, geometric lattice, etc.).
    \item \textbf{Mixing behavior}: Whether the transform is designed for sparsity, diffusion, or invariance.
\end{itemize}

\section{Variant-to-Domain Mapping}
\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lp{7cm}@{}}\toprule
Variant & Recommended Use Cases \\ \midrule
\texttt{original} & General-purpose; fastest; good baseline \\
\texttt{golden} & Quasicrystal analysis; signals with $\phi$-related structure \\
\texttt{fibonacci\_tilt} & PQ crypto experiments; lattice-flavored mixing \\
\texttt{harmonic\_phase} & Audio/music; preserves harmonic relationships \\
\texttt{chaotic\_mix} & Encryption; maximum diffusion; no exploitable structure \\
\texttt{hyperbolic\_phase} & Edge detection; concentrated support in frequency \\
\texttt{log\_periodic} & Text/ASCII compression; mitigates character repetition \\
\texttt{entropy\_mod} & Lossy compression; optimizes energy compaction \\
\texttt{euler\_sphere} & 3D point clouds; rotational invariance \\
\texttt{loxodrome} & Navigation/geodesy; constant-bearing spiral on sphere \\ \bottomrule
\end{tabular}
\end{table}

\section{Diffusion vs. Structure Preservation}
A key design trade-off:
\begin{itemize}
    \item \textbf{Diffusion-heavy variants} (e.g., \texttt{chaotic\_mix}): Every input bit affects many output coefficients. Good for encryption/hashing; poor for sparse recovery.
    \item \textbf{Structure-preserving variants} (e.g., \texttt{golden}, \texttt{harmonic\_phase}): Preserve locality and quasi-periodicity. Good for compression/denoising; poor for cryptographic mixing.
\end{itemize}

\begin{example}[Diffusion Comparison]
Apply a 1-bit flip to input and measure Hamming distance in output:
\begin{lstlisting}[language=Python]
from algorithms.rft.variants.registry import get_variant
import numpy as np

def bit_flip_diffusion(variant_name, N=128):
    var = get_variant(variant_name, N)
    x = np.random.randn(N)
    x_flip = x.copy()
    x_flip[0] += 1e-6  # tiny perturbation
    Y1 = var.forward(x)
    Y2 = var.forward(x_flip)
    return np.sum(np.abs(Y1 - Y2) > 1e-10) / N

print("golden diffusion:", bit_flip_diffusion('golden'))
print("chaotic_mix diffusion:", bit_flip_diffusion('chaotic_mix'))
# Expect chaotic_mix >> golden
\end{lstlisting}
\end{example}

\section{Auto-Selection Heuristics}
The repository includes an experimental auto-selector that examines signal statistics:
\begin{lstlisting}[language=Python, caption={Auto-Selection API}]
from algorithms.rft.variants.auto_select import auto_select_variant

signal = np.sin(2 * np.pi * 0.1 * np.arange(1024))  # periodic
variant = auto_select_variant(signal)
print("Selected:", variant.name)  # likely 'original' or 'harmonic_phase'

texture = np.random.randn(1024) * np.sin(2 * np.pi * 0.618 * np.arange(1024))
variant = auto_select_variant(texture)
print("Selected:", variant.name)  # likely 'golden' or 'entropy_mod'
\end{lstlisting}

\section{Practical Tips}
\begin{itemize}
    \item Start with \texttt{original} as a baseline; compare against specialized variants.
    \item For encryption, always use \texttt{chaotic\_mix} or \texttt{fibonacci\_tilt}.
    \item For medical signals, test \texttt{harmonic\_phase} (preserves beat structure).
    \item Profile with your actual data; synthetic benchmarks may not transfer.
\end{itemize}

\chapter{Wave-Domain Computation}

\begin{todobox}{6}
\begin{itemize}
    \item[$\square$] Derive XOR, AND, OR, NOT in BPSK wave domain.
    \item[$\square$] Implement half-adder as waves; verify correctness.
    \item[$\square$] Measure energy before/after operations.
\end{itemize}
\end{todobox}

\section{BPSK Logic}
Bit $b \in \{0,1\}$ maps to symbol $s=2b-1 \in \{-1,+1\}$. Waveform:
\begin{equation}
    W(t) = \frac{1}{\sqrt{K}} \sum_{k=0}^{K-1} s_k \Psi_k(t)
\end{equation}

\begin{table}[h]
\centering
\begin{tabular}{@{}lll@{}}\toprule
Op & Symbol Rule & Note \\ \midrule
XOR & $-s_a s_b$ & Negate product \\
AND & $+1$ if both $>0$ else $-1$ & Gate via correlation \\
OR  & $+1$ if either $>0$ else $-1$ & Gate via correlation \\
NOT & $-s_a$ & Negation \\ \bottomrule
\end{tabular}
\end{table}

\begin{lstlisting}[language=Python, caption={Wave XOR/AND/OR/NOT}]
from algorithms.rft.core.symbolic_wave_computer import SymbolicWaveComputer
swc = SymbolicWaveComputer(num_bits=8, samples=128)
A, B = 0b10101010, 0b11001100
wa, wb = swc.encode(A), swc.encode(B)
assert swc.decode_int(swc.wave_xor(wa, wb)) == (A ^ B)
assert swc.decode_int(swc.wave_and(wa, wb)) == (A & B)
\end{lstlisting}

\section{Half-Adder in the Wave Domain}
\begin{lstlisting}[language=Python, caption={Half-Adder with Waves}]
from algorithms.rft.core.symbolic_wave_computer import SymbolicWaveComputer
swc = SymbolicWaveComputer(num_bits=2, samples=128)
A, B = 1, 1
wa, wb = swc.encode(A), swc.encode(B)
sum_wave = swc.wave_xor(wa, wb)
carry_wave = swc.wave_and(wa, wb)
print("sum", swc.decode_int(sum_wave), "carry", swc.decode_int(carry_wave))
# Expect sum=0, carry=1
\end{lstlisting}

\section{Energy Considerations}
Wave logic keeps amplitudes near unit magnitude because symbols are $\pm1$. Operations like XOR/NOT preserve energy; AND/OR can skew energy if symbol imbalance grows. Normalize after gates if chaining many operations.

\section{Error Modes}
\begin{itemize}
    \item Finite sampling: too few samples per symbol can raise decode error; keep samples $\ge 64$ for small bit-widths.
    \item Basis mismatch: ensure encode/decode use the same basis (variant and $K$).
    \item Noise: additive noise perturbs correlations; majority-vote or low-pass filtering can mitigate.
\end{itemize}

\section{Performance Tips}
\begin{itemize}
    \item Use BinaryRFT for small $K$ (logic) to skip Gram correction and gain speed.
    \item Batch operations: stack waves and use matrix multiply for XOR/AND across many pairs.
    \item Decode integers in vectorized form to reduce Python overhead.
\end{itemize}

\section{Full Adder and Ripple-Carry Addition}
Extending the half-adder to multi-bit arithmetic:

\begin{lstlisting}[language=Python, caption={4-bit Ripple-Carry Adder in Waves}]
from algorithms.rft.core.symbolic_wave_computer import SymbolicWaveComputer

def wave_full_adder(swc, a_wave, b_wave, cin_wave):
    """Full adder: sum = a XOR b XOR cin, cout = (a AND b) OR (cin AND (a XOR b))"""
    a_xor_b = swc.wave_xor(a_wave, b_wave)
    sum_wave = swc.wave_xor(a_xor_b, cin_wave)
    cout_wave = swc.wave_or(
        swc.wave_and(a_wave, b_wave),
        swc.wave_and(cin_wave, a_xor_b)
    )
    return sum_wave, cout_wave

def wave_ripple_add(swc, A, B, bits=4):
    """Ripple-carry addition of two integers in wave domain."""
    # Encode each bit as a separate wave
    a_waves = [swc.encode((A >> i) & 1) for i in range(bits)]
    b_waves = [swc.encode((B >> i) & 1) for i in range(bits)]
    carry = swc.encode(0)
    sum_waves = []
    for i in range(bits):
        s, carry = wave_full_adder(swc, a_waves[i], b_waves[i], carry)
        sum_waves.append(s)
    # Decode result
    result = sum(swc.decode_int(sum_waves[i]) << i for i in range(bits))
    return result

swc = SymbolicWaveComputer(num_bits=1, samples=64)
print(wave_ripple_add(swc, 5, 3))  # Should print 8
print(wave_ripple_add(swc, 7, 9))  # Should print 16 (mod 16 = 0 for 4-bit)
\end{lstlisting}

\section{Multiplication via Shift-and-Add}
Wave-domain multiplication follows the standard shift-and-add algorithm:
\begin{enumerate}
    \item For each bit $i$ of the multiplier $B$:
    \item If $B[i] = 1$, add $A \ll i$ to the accumulator (in wave form).
    \item Return the accumulated sum.
\end{enumerate}

\begin{remark}
Multiplication is $O(n^2)$ in bit-width $n$ for ripple-carry. For performance-critical paths, consider Karatsuba or NTT-based multiplication (not yet implemented in wave domain).
\end{remark}

\section{Comparison with Digital Logic}
\begin{table}[h]
\centering
\begin{tabular}{@{}lll@{}}\toprule
Property & Digital (CMOS) & Wave-Domain (RFT) \\ \midrule
Gate delay & $\sim$ps & $\sim\mu$s (software) \\
Parallelism & Spatial (many transistors) & Frequency (many carriers) \\
Noise margin & High (digital thresholds) & Moderate (correlation-based) \\
Energy model & Switching energy & Amplitude energy \\
Error correction & Explicit (ECC) & Implicit (redundant carriers) \\ \bottomrule
\end{tabular}
\end{table}

Wave-domain computation is not intended to replace digital logic but to explore alternative computational substrates (e.g., analog hardware, optical systems) where frequency-multiplexed signals are natural.

% PART III: QUANTUM --------------------------------------------------------
\part{Quantum Simulation}

\chapter{Quantum Fundamentals}

\begin{todobox}{7}
\begin{itemize}
    \item[$\square$] Write $|\psi\rangle = \alpha|0\rangle+\beta|1\rangle$; normalization.
    \item[$\square$] Verify Hadamard is unitary; compute $H|0\rangle$.
    \item[$\square$] Form tensor products for 2-qubit states.
    \item[$\square$] Implement a simple quantum circuit and simulate it.
\end{itemize}
\end{todobox}

\section{Qubits as State Vectors}
A single qubit state is a unit vector in $\mathbb{C}^2$:
\begin{equation}
|\psi\rangle = \alpha|0\rangle + \beta|1\rangle,\qquad |\alpha|^2 + |\beta|^2 = 1.
\end{equation}
Only relative phase matters: $|\psi\rangle$ and $e^{i\gamma}|\psi\rangle$ represent the same physical state.

\begin{example}[Common Single-Qubit States]
\begin{align}
|0\rangle &= \begin{pmatrix} 1 \\ 0 \end{pmatrix}, &
|1\rangle &= \begin{pmatrix} 0 \\ 1 \end{pmatrix}, \\
|+\rangle &= \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1 \end{pmatrix}, &
|-\rangle &= \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ -1 \end{pmatrix}, \\
|i\rangle &= \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ i \end{pmatrix}, &
|-i\rangle &= \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ -i \end{pmatrix}.
\end{align}
\end{example}

\section{Measurement (Born Rule)}
Measuring in the computational basis returns outcome $0$ with probability $|\alpha|^2$ and outcome $1$ with probability $|\beta|^2$. After measurement, the state collapses to the observed basis vector.

\begin{example}[Measurement Statistics]
For $|\psi\rangle = \frac{1}{\sqrt{3}}|0\rangle + \sqrt{\frac{2}{3}}|1\rangle$:
\begin{itemize}
    \item $P(0) = |1/\sqrt{3}|^2 = 1/3$
    \item $P(1) = |\sqrt{2/3}|^2 = 2/3$
\end{itemize}
\end{example}

\section{Multi-Qubit Systems and Tensor Products}
An $n$-qubit register lives in a $2^n$-dimensional complex vector space. Basis states are tensor products:
\begin{equation}
|b_{n-1}\dots b_1 b_0\rangle = |b_{n-1}\rangle \otimes \cdots \otimes |b_1\rangle \otimes |b_0\rangle.
\end{equation}
Operators compose likewise. If $A$ acts on qubit 0 and $B$ acts on qubit 1, then the joint operator is $B\otimes A$ (ordering is convention-dependent).

\begin{example}[Bell State]
The Bell state $|\Phi^+\rangle = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)$ is:
\begin{equation}
|\Phi^+\rangle = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 0 \\ 0 \\ 1 \end{pmatrix}
\end{equation}
This state is \textbf{entangled}: it cannot be written as $|\psi_A\rangle \otimes |\psi_B\rangle$.
\end{example}

\section{Unitary Gates}
Gates in ideal quantum computing are unitary matrices $U$ satisfying $U^\dagger U = I$. Unitarity preserves normalization and inner products:
\begin{equation}
\|U|\psi\rangle\|_2 = \||\psi\rangle\|_2.
\end{equation}
This is the same stability criterion used earlier for Gram-corrected RFT: numerically, unitary maps are maximally well-conditioned.

\section{Standard Gate Matrices}
\begin{align}
X &= \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}, &
Y &= \begin{pmatrix} 0 & -i \\ i & 0 \end{pmatrix}, &
Z &= \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}, \\
H &= \frac{1}{\sqrt{2}}\begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix}, &
S &= \begin{pmatrix} 1 & 0 \\ 0 & i \end{pmatrix}, &
T &= \begin{pmatrix} 1 & 0 \\ 0 & e^{i\pi/4} \end{pmatrix}.
\end{align}

The CNOT (controlled-NOT) gate on 2 qubits:
\begin{equation}
\text{CNOT} = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \end{pmatrix}.
\end{equation}

\section{Common Gates in QuantoniumOS}
QuantoniumOS provides a gate library in \texttt{algorithms/rft/quantum/quantum\_gates.py}. The implementation uses explicit matrices and validates unitarity at construction.
\begin{lstlisting}[language=Python, caption={Inspecting Gate Matrices}]
from algorithms.rft.quantum.quantum_gates import H, X, Z, CNOT

print(H.name, H.matrix)
print(X.name, X.matrix)
print(Z.name, Z.matrix)
print(CNOT.name, CNOT.matrix)
\end{lstlisting}

\section{Building Quantum Circuits}
\begin{lstlisting}[language=Python, caption={Creating a Bell State}]
import numpy as np
from algorithms.rft.quantum.quantum_gates import H, CNOT

def create_bell_state():
    """Create |Phi+> = (|00> + |11>) / sqrt(2)"""
    # Start with |00>
    state = np.array([1, 0, 0, 0], dtype=complex)
    
    # Apply H to qubit 0: H tensor I
    H_I = np.kron(np.eye(2), H.matrix)
    state = H_I @ state
    
    # Apply CNOT (control=0, target=1)
    state = CNOT.matrix @ state
    
    return state

bell = create_bell_state()
print("Bell state:", bell)
# [0.707, 0, 0, 0.707]
\end{lstlisting}

\section{Cost of Classical Simulation}
QuantoniumOS uses state-vector simulation: an $n$-qubit state is a length-$2^n$ complex vector. Memory and time scale as $\Theta(2^n)$, so practical experiments usually stay below a few dozen qubits depending on hardware.

\begin{table}[h]
\centering
\begin{tabular}{@{}lrr@{}}\toprule
Qubits & State Vector Size & Approx. Memory \\ \midrule
10 & 1,024 & 16 KB \\
20 & 1,048,576 & 16 MB \\
30 & 1,073,741,824 & 16 GB \\
40 & $\sim 10^{12}$ & 16 TB \\ \bottomrule
\end{tabular}
\caption{Memory requirements for state-vector simulation (complex128).}
\end{table}

\chapter{Grover's Algorithm}

\begin{todobox}{8}
\begin{itemize}
    \item[$\square$] State the search problem and classical $O(N)$ bound.
    \item[$\square$] Derive Grover iteration count $\lfloor \frac{\pi}{4}\sqrt{N} \rfloor$.
    \item[$\square$] Run the provided \texttt{QuantumSearch} example.
\end{itemize}
\end{todobox}

\section{Problem Statement}
Given an unstructured set of $N$ items with exactly one marked element, classical search takes $\Theta(N)$ queries in the worst case. Grover's algorithm finds the marked element using $\Theta(\sqrt{N})$ oracle calls.

\section{Grover Iterate}
Grover's method alternates two reflections:
\begin{itemize}
    \item Oracle: flips the phase of the marked basis state, $|x^*\rangle \mapsto -|x^*\rangle$.
    \item Diffusion: reflects about the uniform superposition $|s\rangle$.
\end{itemize}
The iterate is $G = D\,O$.

\section{Two-Dimensional Reduction and Iteration Count}
Let $|x^*\rangle$ be the marked state and let $|\omega\rangle$ be the normalized superposition of all unmarked states. The state evolution remains in the span of $\{|x^*\rangle, |\omega\rangle\}$.
Write the initial uniform superposition as
\begin{equation}
|s\rangle = \sin(\theta)\,|x^*\rangle + \cos(\theta)\,|\omega\rangle,\qquad \sin(\theta)=\frac{1}{\sqrt{N}}.
\end{equation}
Each Grover step rotates the state by angle $2\theta$ toward $|x^*\rangle$:
\begin{equation}
G^k|s\rangle = \sin((2k+1)\theta)\,|x^*\rangle + \cos((2k+1)\theta)\,|\omega\rangle.
\end{equation}
Choose $k$ so that $(2k+1)\theta\approx \pi/2$, giving $k\approx \frac{\pi}{4}\sqrt{N}$ for large $N$.

\section{How QuantoniumOS Implements It}
The implementation in \texttt{algorithms/rft/quantum/quantum\_search.py} is a faithful state-vector simulation:
\begin{itemize}
    \item Uses $n=\lceil\log_2 N\rceil$ qubits and dimension $\mathrm{dim}=2^n$.
    \item Builds $H^{\otimes n}$ by repeated Kronecker products.
    \item Oracle is a diagonal matrix with a single $-1$ entry at \texttt{target\_index}.
    \item Diffusion is $H^{\otimes n}(2|0\rangle\langle 0|-I)H^{\otimes n}$.
    \item Measures by taking \texttt{argmax} of probabilities (deterministic readout of the dominant amplitude).
\end{itemize}

\begin{remark}
Because $\mathrm{dim}$ may exceed $N$, the simulator checks that the measured index maps back into the container list. This is a pragmatic detail of embedding $N$ items into a power-of-two Hilbert space.
\end{remark}

\begin{lstlisting}[language=Python, caption={Grover in QuantoniumOS}]
from algorithms.rft.quantum.quantum_search import QuantumSearch
from algorithms.rft.core.geometric_container import GeometricContainer

containers = [GeometricContainer(id=f"C{i}", capacity_bits=128) for i in range(8)]
containers[3].encode_data("TARGET")
qs = QuantumSearch()
found = qs.search(containers, target_index=3)
print(found.id)
\end{lstlisting}

\section{Amplitude Amplification Generalization}
Grover's algorithm is a special case of \textbf{amplitude amplification}. Given any algorithm $\mathcal{A}$ that produces a "good" state with probability $a$, amplitude amplification boosts the success probability to near 1 using $O(1/\sqrt{a})$ calls to $\mathcal{A}$ and its inverse.

\begin{theorem}[Amplitude Amplification]
Let $\mathcal{A}$ be a quantum algorithm such that
\begin{equation}
\mathcal{A}|0\rangle = \sqrt{a}|\psi_{\text{good}}\rangle + \sqrt{1-a}|\psi_{\text{bad}}\rangle.
\end{equation}
Then $O(1/\sqrt{a})$ applications of the amplification operator yield a state with $\Omega(1)$ probability of being in $|\psi_{\text{good}}\rangle$.
\end{theorem}

\section{Multiple Marked Items}
If there are $M$ marked items among $N$ total:
\begin{itemize}
    \item Optimal iterations: $k \approx \frac{\pi}{4}\sqrt{N/M}$
    \item Success probability approaches 1 when $M \ll N$
    \item When $M$ is unknown, use quantum counting first
\end{itemize}

\begin{lstlisting}[language=Python, caption={Grover with Multiple Targets}]
# Conceptual: mark items 2, 5, 7 in a list of 16
def multi_target_oracle(dim, targets):
    """Oracle that flips phase of multiple target indices."""
    import numpy as np
    oracle = np.eye(dim)
    for t in targets:
        oracle[t, t] = -1
    return oracle

# Iterations: floor((pi/4) * sqrt(16/3)) ~ 2
\end{lstlisting}

\section{Limitations and Practical Notes}
\begin{itemize}
    \item \textbf{Oracle access}: Grover requires a quantum oracle. Constructing this oracle for a classical function can be expensive.
    \item \textbf{Quadratic speedup only}: Grover does not provide exponential speedup; for $N$ items, it still requires $O(\sqrt{N})$ queries.
    \item \textbf{Exact iteration count}: Overshooting the optimal $k$ reduces success probability. In practice, use $k = \lfloor \frac{\pi}{4}\sqrt{N/M} \rfloor$.
    \item \textbf{QuantoniumOS scope}: The simulator is for education and small-scale experiments, not cryptographic applications.
\end{itemize}

\section{Exercises}
\begin{enumerate}
    \item Implement Grover for $N=4$ by hand (2 qubits). Verify the state after each iteration.
    \item Modify the oracle to mark two items. How does the iteration count change?
    \item What happens if you apply too many Grover iterations? Plot success probability vs. $k$.
\end{enumerate}

% PART IV: VALIDATION AND PRACTICAL USE ------------------------------------
\part{Validation and Practical Use}

\chapter{Real Performance: Measured Results}

This chapter presents actual benchmark results from the repository, with honest assessment of where RFT helps and where it does not.

\section{The Core Question}
Before investing time in a new transform, practitioners need answers to:
\begin{enumerate}
    \item \textbf{What are the actual measured gains?} (Not theoretical, not projected)
    \item \textbf{On what signal classes?} (Specific, reproducible conditions)
    \item \textbf{At what cost?} (Runtime, memory, complexity)
    \item \textbf{How do I verify this myself?} (Reproducible benchmarks)
\end{enumerate}

\section{Measured Fidelity Results}
The following data is extracted from \texttt{data/quantum\_compression\_results.json}, representing actual benchmark runs.

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}llccc@{}}\toprule
Signal Type & Keep \% & RFT Fidelity & DCT Fidelity & FFT Fidelity \\ \midrule
\multirow{4}{*}{Golden Coherent} & 5\% & \textbf{0.354} & 0.272 & 0.354 \\
 & 10\% & \textbf{0.643} & 0.495 & 0.643 \\
 & 20\% & \textbf{0.913} & 0.758 & 0.913 \\
 & 30\% & \textbf{0.977} & 0.900 & 0.977 \\ \midrule
\multirow{4}{*}{Penrose Tiling} & 5\% & \textbf{0.999} & 0.994 & 0.999 \\
 & 10\% & \textbf{0.999} & 0.997 & 0.999 \\
 & 20\% & \textbf{1.000} & 0.999 & 1.000 \\
 & 30\% & \textbf{1.000} & 0.999 & 1.000 \\ \midrule
\multirow{4}{*}{Random Control} & 5\% & 0.197 & \textbf{0.281} & 0.197 \\
 & 10\% & 0.333 & \textbf{0.434} & 0.333 \\
 & 20\% & 0.535 & \textbf{0.640} & 0.535 \\
 & 30\% & 0.676 & \textbf{0.781} & 0.676 \\ \bottomrule
\end{tabular}
\caption{Measured fidelity (higher = better) at various coefficient retention levels. RFT wins on $\phi$-structured signals, loses on random signals.}
\end{table}

\begin{keyconceptbox}
\textbf{Key Finding}: RFT shows 15--30\% fidelity improvement on golden-coherent and Penrose-tiling signals at low retention rates (5--10\%). On random signals, DCT wins by 8--15\%. This confirms the domain-specific nature of the transform.
\end{keyconceptbox}

\section{Where RFT Wins}
Based on measured benchmarks, RFT outperforms alternatives on:
\begin{itemize}
    \item \textbf{Penrose tiling patterns}: 99.9\% fidelity at 5\% retention (vs. 99.4\% DCT)
    \item \textbf{Golden-ratio coherent signals}: 35\% fidelity at 5\% retention (vs. 27\% DCT)
    \item \textbf{Quasicrystal structures}: Strong performance on $\phi$-structured data
    \item \textbf{Fibonacci quasiperiodic}: ~20\% fidelity at 5\% (vs. 14\% DCT)
\end{itemize}

\section{Where RFT Loses}
Equally important---where RFT performs \textbf{worse}:
\begin{itemize}
    \item \textbf{Random noise}: DCT wins by 8--15\% at all retention levels
    \item \textbf{Smooth piecewise signals}: DCT's low-frequency concentration is superior
    \item \textbf{General images without texture}: Standard JPEG-style DCT is better
    \item \textbf{Runtime}: RFT is slower than FFT (see complexity analysis)
\end{itemize}

\begin{warningbox}
\textbf{Honest Assessment}: For general-purpose signal processing, stick with FFT/DCT. RFT is a \textbf{specialized tool} for a \textbf{specific signal class}.
\end{warningbox}

\section{Unitarity and Numerical Stability}
From \texttt{data/scaling\_results.json}, unitarity error across variants:

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lrrrrr@{}}\toprule
Variant & N=32 & N=64 & N=128 & N=256 & N=512 \\ \midrule
Original $\Phi$-RFT & 3.7e-15 & 7.0e-15 & 1.2e-14 & 2.1e-14 & 3.3e-14 \\
Harmonic-Phase & 3.7e-15 & 6.9e-15 & 1.2e-14 & 2.1e-14 & 3.4e-14 \\
Fibonacci Tilt & 3.2e-15 & 6.9e-15 & 1.2e-14 & 2.3e-14 & 4.4e-14 \\
Chaotic Mix & 4.2e-15 & 6.8e-15 & 1.2e-14 & 2.1e-14 & 3.4e-14 \\ \bottomrule
\end{tabular}
\caption{Unitarity error $\|U^\dagger U - I\|$ across sizes. All variants maintain machine-precision unitarity.}
\end{table}

\section{Reproducing These Results}
\begin{lstlisting}[language=bash, caption={Benchmark Reproduction Commands}]
# Clone repository
git clone https://github.com/mandcony/quantoniumos.git
cd quantoniumos

# Install dependencies
pip install -r requirements.txt

# Run compression benchmark (generates quantum_compression_results.json)
python benchmarks/class_c_compression.py

# Run scaling benchmark (generates scaling_results.json)
python benchmarks/rft_phi_frame_benchmark.py

# Verify results match expected values
python tests/validation/test_benchmark_reproducibility.py
\end{lstlisting}

\chapter{When to Use RFT}

\section{Decision Framework}
Use this flowchart to determine if RFT is appropriate for your application:

\begin{center}
\begin{tikzpicture}[
    node distance=1.2cm,
    decision/.style={diamond, draw, aspect=2, minimum width=3cm, minimum height=1cm, align=center, fill=yellow!20},
    block/.style={rectangle, draw, minimum width=2.5cm, minimum height=0.7cm, align=center},
    yes/.style={->, thick, green!60!black},
    no/.style={->, thick, red!60!black}
]
    \node[decision] (q1) {Signal has $\phi$-structure?};
    \node[decision, below=of q1] (q2) {Sparsity > Speed?};
    \node[decision, below=of q2] (q3) {Can precompute basis?};
    \node[block, fill=green!20, below=of q3] (use) {Use RFT};
    \node[block, fill=red!20, right=3cm of q1] (fft1) {Use FFT/DCT};
    \node[block, fill=red!20, right=3cm of q2] (fft2) {Use FFT/DCT};
    \node[block, fill=red!20, right=3cm of q3] (fft3) {Use FFT/DCT};
    
    \draw[yes] (q1) -- node[left] {Yes} (q2);
    \draw[no] (q1) -- node[above] {No} (fft1);
    \draw[yes] (q2) -- node[left] {Yes} (q3);
    \draw[no] (q2) -- node[above] {No} (fft2);
    \draw[yes] (q3) -- node[left] {Yes} (use);
    \draw[no] (q3) -- node[above] {No} (fft3);
\end{tikzpicture}
\end{center}

\section{Good Use Cases}
\begin{description}
    \item[Quasicrystal analysis] Penrose tilings, aperiodic structures, materials science.
    \item[Biosignal compression] ECG/EEG with quasi-periodic morphology.
    \item[Texture-heavy image compression] When residual after DCT has quasi-periodic structure.
    \item[Feature extraction for ML] When $\phi$-structured features improve classification.
    \item[Offline processing] When runtime is not critical and quality matters.
\end{description}

\section{Poor Use Cases}
\begin{description}
    \item[Real-time spectral analysis] FFT is 10--100$\times$ faster.
    \item[General filtering] Convolution theorem makes FFT superior.
    \item[Random/noisy signals] No structure to exploit; DCT wins.
    \item[Embedded systems] Memory for basis storage may be prohibitive.
    \item[Smooth signals] DCT energy compaction is superior.
\end{description}

\section{Cost-Benefit Analysis}
\begin{table}[h]
\centering
\begin{tabular}{@{}lll@{}}\toprule
Factor & RFT Cost & RFT Benefit \\ \midrule
Computation & $O(N^2)$ naive, $O(N\log N)$ fast & Better sparsity on $\phi$-signals \\
Memory & Basis matrix storage & One-time precomputation \\
Complexity & More code, more parameters & Domain-specific optimization \\
Validation & Less ecosystem support & Novel research direction \\ \bottomrule
\end{tabular}
\end{table}

\section{Practical Recommendations}
\begin{enumerate}
    \item \textbf{Start with FFT/DCT}. Only switch to RFT if you have evidence of $\phi$-structure.
    \item \textbf{Run both and compare}. The benchmarks make this easy.
    \item \textbf{Check your signal class}. Use the taxonomy in Chapter~3.
    \item \textbf{Measure, don't assume}. Domain intuition can be wrong.
    \item \textbf{Consider hybrid approaches}. H3 cascade uses both DCT and RFT.
\end{enumerate}

\chapter{Validating Core Claims}

This chapter provides a rigorous framework for evaluating the claims made in this textbook and the QuantoniumOS repository.

\section{Claim Hierarchy}
Not all claims are equal. We distinguish:

\begin{table}[h]
\centering
\begin{tabular}{@{}lll@{}}\toprule
Level & Claim Type & Validation Method \\ \midrule
\textbf{Mathematical} & Definitions, theorems & Proof verification \\
\textbf{Algorithmic} & Complexity, correctness & Code inspection + testing \\
\textbf{Empirical} & Performance gains & Reproducible benchmarks \\
\textbf{Practical} & Use-case suitability & Case studies, user feedback \\ \bottomrule
\end{tabular}
\end{table}

\section{What We Claim (and Don't Claim)}
\begin{table}[h]
\centering
\small
\begin{tabular}{@{}p{5cm}p{5cm}l@{}}\toprule
\textbf{We Claim} & \textbf{We Do NOT Claim} & \textbf{Evidence} \\ \midrule
Novel point in transform design space & Revolutionary breakthrough & Definition \\
Domain-specific sparsity on $\phi$-signals & Universal superiority over FFT & Benchmarks \\
Data-independent KLT-like compaction & Better than adaptive transforms & Theory \\
Educational quantum simulator & Real quantum speedup & Code \\
Hardware feasibility study & Production ASIC & RTL sims \\
Research-only crypto primitives & Cryptographic security & Warnings \\ \bottomrule
\end{tabular}
\end{table}

\section{Validation Protocol}
To validate claims yourself:

\subsection{Step 1: Verify Mathematical Foundations}
\begin{lstlisting}[language=Python, caption={Verify Unitarity}]
import numpy as np
from algorithms.rft.core.canonical_true_rft import CanonicalTrueRFT

rft = CanonicalTrueRFT(size=256)
Phi = rft.get_basis_matrix()

# Check unitarity: U^H U should be identity
UhU = Phi.conj().T @ Phi
identity_error = np.linalg.norm(UhU - np.eye(256))
print(f"Unitarity error: {identity_error:.2e}")
assert identity_error < 1e-10, "Unitarity violated!"
\end{lstlisting}

\subsection{Step 2: Verify Round-Trip Reconstruction}
\begin{lstlisting}[language=Python, caption={Verify Perfect Reconstruction}]
import numpy as np
from algorithms.rft.core.canonical_true_rft import CanonicalTrueRFT

rft = CanonicalTrueRFT(size=256)

# Random test signal
x = np.random.randn(256) + 1j * np.random.randn(256)

# Forward + inverse
X = rft.forward_transform(x)
x_reconstructed = rft.inverse_transform(X)

# Check reconstruction error
recon_error = np.linalg.norm(x - x_reconstructed) / np.linalg.norm(x)
print(f"Reconstruction error: {recon_error:.2e}")
assert recon_error < 1e-10, "Reconstruction failed!"
\end{lstlisting}

\subsection{Step 3: Verify Sparsity Claims}
\begin{lstlisting}[language=Python, caption={Compare Sparsity Across Transforms}]
import numpy as np
from algorithms.rft.core.canonical_true_rft import CanonicalTrueRFT

def sparsity_metric(coeffs, threshold=0.01):
    """Count coefficients above threshold (normalized)."""
    normalized = np.abs(coeffs) / np.max(np.abs(coeffs))
    return np.sum(normalized > threshold) / len(coeffs)

# Generate golden-ratio structured signal
PHI = (1 + np.sqrt(5)) / 2
t = np.arange(256) / 256
signal = np.cos(2 * np.pi * PHI * t) + 0.5 * np.cos(2 * np.pi * PHI**2 * t)

# Compare transforms
rft = CanonicalTrueRFT(size=256)
rft_coeffs = rft.forward_transform(signal)
fft_coeffs = np.fft.fft(signal)

print(f"RFT sparsity: {sparsity_metric(rft_coeffs):.3f}")
print(f"FFT sparsity: {sparsity_metric(fft_coeffs):.3f}")
# RFT should have lower sparsity (fewer significant coefficients)
\end{lstlisting}

\subsection{Step 4: Run Official Benchmarks}
\begin{lstlisting}[language=bash]
# Run all benchmarks with fixed seeds
python benchmarks/run_all_benchmarks.py --seed 42 --output results/

# Compare against baseline
python scripts/compare_baseline.py results/
\end{lstlisting}

\section{Red Flags and Honest Limitations}

\begin{warningbox}
\textbf{Limitations You Should Know:}
\begin{itemize}
    \item RFT is $O(N^2)$ in naive implementation (fast version is $O(N\log N)$)
    \item Higher constant factors than FFT even in fast mode
    \item Memory overhead for storing non-trivial basis matrices
    \item Limited ecosystem support (no FFTW-style optimized libraries)
    \item Domain mismatch causes \textbf{worse} performance than alternatives
\end{itemize}
\end{warningbox}

\section{Independent Verification Checklist}
\begin{enumerate}
    \item[$\square$] Clone repository from scratch on clean machine
    \item[$\square$] Install dependencies with exact versions (\texttt{requirements-lock.txt})
    \item[$\square$] Run unit tests (\texttt{pytest tests/})
    \item[$\square$] Run benchmark suite with fixed seed
    \item[$\square$] Compare output against \texttt{data/*.json} reference files
    \item[$\square$] Verify mathematical properties (unitarity, reconstruction)
    \item[$\square$] Test on your own signals---do results match signal class predictions?
    \item[$\square$] Read \texttt{docs/LIMITATIONS\_AND\_REVIEWER\_CONCERNS.md}
\end{enumerate}

\section{Addressing Common Criticisms}

\subsection{``Isn't this just a windowed FFT?''}
\textbf{No.} The windowed FFT multiplies by a window function before FFT. RFT uses entirely different basis vectors derived from golden-ratio frequency spacing. The eigenstructure is different.

\subsection{``Why is it slower than FFT?''}
\textbf{Because eigendecomposition is inherently more expensive.} FFT exploits circulant structure for $O(N\log N)$. RFT exploits Toeplitz structure, which is less efficient. This is acceptable when sparsity matters more than speed.

\subsection{``Aren't the benchmarks cherry-picked?''}
\textbf{We show failure cases explicitly.} Random control signals, smooth signals, and out-of-family signals show RFT \textbf{losing}. The benchmark suite includes these to prevent cherry-picking.

\subsection{``The quantum naming is misleading.''}
\textbf{Agreed.} The name is historical. There is no quantum computation in this work. It is purely classical signal processing.

\section{Exercises}
\begin{enumerate}
    \item Run the validation protocol on your machine. Do results match the book?
    \item Generate a signal from each class in the taxonomy. Which transform wins for each?
    \item Modify a benchmark to use a different random seed. Do conclusions change?
    \item Find a signal class where RFT significantly \textbf{underperforms}. Document it.
\end{enumerate}

% PART V: APPLICATIONS ----------------------------------------------------
\part{Applications}

\chapter{Hybrid Compression: H3 Cascade}

\begin{todobox}{9}
\begin{itemize}
    \item[$\square$] Explain structure-texture split (wavelet front-end).
    \item[$\square$] Show why DCT suits structure; RFT suits texture.
    \item[$\square$] Run \texttt{benchmark\_h3\_arft.py}; record PSNR/BPP.
\end{itemize}
\end{todobox}

\section{Motivation: Structure vs. Texture}
Many compression systems implicitly separate an input into (i) smooth, slowly varying components and (ii) fine-grained residual structure. In QuantoniumOS, the H3 cascade makes this explicit:
\begin{itemize}
    \item \textbf{Structure}: edges, low-frequency gradients, and coherent large-scale features.
    \item \textbf{Texture}: quasi-periodic microstructure, fine oscillations, and locally stationary residuals.
\end{itemize}
The goal is not to replace DCT-based coding, but to complement it in regimes where texture energy is better represented in a quasi-periodic basis.

\section{Pipeline Overview}
The conceptual pipeline is:
\begin{equation}
	ext{Wavelet Split} \;\to\; \text{Structure (DCT)} + \text{Texture (RFT/ARFT)} \;\to\; \text{Quantize} \;\to\; \text{Entropy (ANS)}.
\end{equation}
In practice, the implementation uses conventional numeric blocks for the structure path and a resonant basis (often a fast or approximate RFT variant) for the texture path.

\section{Why DCT for Structure?}
DCT is strong on smooth regions and piecewise-regular signals because most energy concentrates in low-frequency coefficients when the signal is locally correlated. This yields a high compression ratio after quantization and entropy coding.

\section{Why RFT/ARFT for Texture?}
Texture often contains quasi-periodic elements that do not align well with integer-spaced Fourier bins. The golden-ratio spacing used by the RFT reduces phase locking and can concentrate energy into fewer coefficients for certain textured residuals.

\section{Benchmarking and Reproducibility}
The repository includes a benchmark harness for the hybrid cascade. A typical run is:
\begin{verbatim}
python benchmarks/benchmark_h3_arft.py
\end{verbatim}
Record at minimum:
\begin{itemize}
    \item \textbf{PSNR} (dB) vs. bitrate,
    \item \textbf{BPP} (bits-per-pixel) or an equivalent bitrate measure,
    \item Runtime and peak memory.
\end{itemize}
If results vary across machines, note CPU model, BLAS backend, and NumPy version.

\section{Example: Compressing a Texture Image}
\begin{lstlisting}[language=Python, caption={H3 Cascade Example}]
import numpy as np
from algorithms.rft.compression.h3_cascade import H3Cascade

# Load a grayscale texture image (e.g., 256x256)
image = np.random.randn(256, 256)  # placeholder

h3 = H3Cascade(
    wavelet='db4',
    structure_transform='dct',
    texture_transform='golden_rft',
    quantization_bits=8
)

# Compress
compressed = h3.encode(image)
print(f"Compression ratio: {image.nbytes / len(compressed.data):.2f}x")

# Decompress
reconstructed = h3.decode(compressed)

# Quality metric
mse = np.mean((image - reconstructed) ** 2)
psnr = 10 * np.log10(255**2 / mse) if mse > 0 else float('inf')
print(f"PSNR: {psnr:.2f} dB")
\end{lstlisting}

\section{Tuning Parameters}
\begin{itemize}
    \item \textbf{Wavelet choice}: \texttt{db4} for general images; \texttt{haar} for speed; \texttt{bior4.4} for smoother reconstruction.
    \item \textbf{RFT variant}: \texttt{golden\_rft} is default; try \texttt{entropy\_mod} for better energy compaction.
    \item \textbf{Quantization bits}: 8 for visually lossless; 4--6 for aggressive compression.
    \item \textbf{Block size}: 8$\times$8 for JPEG-like; 16$\times$16 or 32$\times$32 for modern codecs.
\end{itemize}

\section{Rate-Distortion Analysis}
\begin{keyconceptbox}
\textbf{Rate-Distortion Theory}: For a given bitrate budget, there is an optimal trade-off between compression ratio and reconstruction quality. The H3 cascade aims to operate closer to this theoretical limit for textured regions than DCT-only methods.
\end{keyconceptbox}

Experimentally, plot PSNR vs. BPP for multiple test images and compare H3 against:
\begin{itemize}
    \item JPEG (DCT-only)
    \item JPEG2000 (wavelet-only)
    \item H3 with DCT-only texture path (ablation)
\end{itemize}

\chapter{Post-Quantum Cryptography}

\begin{todobox}{10}
\begin{itemize}
    \item[$\square$] Define SIS problem; note research-only status.
    \item[$\square$] Explain RFT-SIS hash intuition (phase lattice).
    \item[$\square$] Run crypto benchmarks (research, not production).
\end{itemize}
\end{todobox}

\section{Status and Scope}
QuantoniumOS crypto modules are \textbf{experimental and research-only}. They are included to explore whether resonance-driven mixing functions and phase-lattice constructions can be useful primitives in a future post-quantum setting. This text does \textbf{not} claim production security.

\section{SIS (Short Integer Solution) in One Page}
The SIS problem is a lattice-style hardness assumption. In a simplified form: given a random matrix $A\in\mathbb{Z}_q^{m\times n}$, find a short nonzero vector $x\in\mathbb{Z}^n$ such that
\begin{equation}
Ax \equiv 0 \pmod q,\qquad \|x\| \text{ is small}.
\end{equation}
Hardness is believed to hold for suitable parameter choices and is related to worst-case lattice problems.

\section{RFT-Flavored Intuition (Not a Proof)}
QuantoniumOS explores the idea that quasi-periodic phases can act like a structured mixing layer. Informally:
\begin{itemize}
    \item RFT bases provide deterministic but low-coherence projections.
    \item Repeated rounds of phase mixing can emulate diffusion across coordinates.
    \item A lattice-style viewpoint treats phase increments as a constrained walk in a high-dimensional modular space.
\end{itemize}
This is an intuition-building picture, not a security argument.

\section{Practical Guidance}
If you run the crypto benchmarks, treat results as \textbf{performance experiments} (throughput, avalanche behavior, distributional checks), not as assurance. For reproducibility, keep the exact script name and CLI flags in your notes and record the git commit hash.

\section{EnhancedRFTCryptoV2 Architecture}
The repository includes an experimental Feistel-style cipher:
\begin{itemize}
    \item \textbf{48 rounds} of RFT-based mixing
    \item \textbf{Key schedule} derived from RFT of the master key
    \item \textbf{S-box equivalent} via nonlinear phase modulation
\end{itemize}

\begin{lstlisting}[language=Python, caption={Experimental Cipher Usage}]
from algorithms.rft.crypto.enhanced_rft_crypto_v2 import EnhancedRFTCryptoV2

cipher = EnhancedRFTCryptoV2(key=b'sixteen_byte_key')
plaintext = b'Hello, QuantoniumOS!'
ciphertext = cipher.encrypt(plaintext)
decrypted = cipher.decrypt(ciphertext)
assert decrypted == plaintext
\end{lstlisting}

\begin{warningbox}
This cipher has \textbf{no security proofs}. Do not use for any real-world application. It exists solely to explore whether RFT mixing has useful cryptographic properties.
\end{warningbox}

\section{Avalanche Effect Testing}
A good cipher should exhibit the \textbf{avalanche effect}: flipping one input bit should flip approximately 50\% of output bits.

\begin{lstlisting}[language=Python, caption={Avalanche Test}]
import numpy as np

def avalanche_test(cipher, num_trials=1000):
    """Measure avalanche effect for a cipher."""
    flip_counts = []
    for _ in range(num_trials):
        plaintext = np.random.bytes(16)
        ct1 = cipher.encrypt(plaintext)
        
        # Flip one random bit
        pt_array = bytearray(plaintext)
        byte_idx = np.random.randint(16)
        bit_idx = np.random.randint(8)
        pt_array[byte_idx] ^= (1 << bit_idx)
        ct2 = cipher.encrypt(bytes(pt_array))
        
        # Count differing bits
        diff = sum(bin(a ^ b).count('1') for a, b in zip(ct1, ct2))
        flip_counts.append(diff)
    
    return np.mean(flip_counts), np.std(flip_counts)

# Ideal: mean ~ 64 (half of 128 bits), low std
\end{lstlisting}

\section{Hash Functions and SIS-RFT}
The SIS-RFT hash explores collision resistance via RFT structure:
\begin{equation}
H(m) = \text{RFT}(m \cdot A) \mod q
\end{equation}
where $A$ is a public matrix and $q$ is a modulus. Finding collisions requires solving a short-vector problem in the RFT-structured lattice.

\begin{remark}
This is a research direction, not a deployable hash function. Standard hash functions (SHA-3, BLAKE3) should be used for any practical application.
\end{remark}

\chapter{Hardware: RFTPU}

\begin{todobox}{11}
\begin{itemize}
    \item[$\square$] List 16 modes in \texttt{fpga\_top.json}; identify 0,6,12,14 as verified.
    \item[$\square$] Describe NoC and tile array briefly.
    \item[$\square$] Run simulation harness (WebFPGA/OpenLane configs).
\end{itemize}
\end{todobox}

\section{What RFTPU Is (and Is Not)}
RFTPU is an accelerator feasibility study: a hardware architecture and simulation environment for executing resonance-related kernels. It is \textbf{not} presented as a shipping ASIC, and results should be read as experimental.

\section{Top-Level Integration}
The hardware directory includes a top-level design and configuration artifacts such as \texttt{hardware/fpga\_top.json} and SystemVerilog sources. A minimal orientation pass is to read \texttt{hardware/README.md} and then identify:
\begin{itemize}
    \item Top-level module wiring,
    \item Kernel ROM cases,
    \item Testbench entry points under \texttt{hardware/tb}.
\end{itemize}

\section{Modes and Capability Tests}
The design advertises multiple modes (kernels). A practical starting point is to run the capabilities test script:
\begin{verbatim}
python hardware/run_capabilities_test.py
\end{verbatim}
Record which modes pass and the observed cycle counts or output hashes.

\section{Simulation and Synthesis Artifacts}
The repository includes simulation outputs and synthesis collateral (e.g., OpenLane configs). Keep a strict separation between:
\begin{itemize}
    \item \textbf{Functional correctness} (testbench passes),
    \item \textbf{Timing/area estimates} (toolchain-dependent),
    \item \textbf{Claims} (do not over-interpret estimates as silicon results).
\end{itemize}

\section{RFTPU Architecture Overview}
\begin{center}
\begin{tikzpicture}[
    node distance=1.5cm,
    block/.style={rectangle, draw, minimum width=2.5cm, minimum height=0.8cm, align=center},
    arrow/.style={->, thick}
]
    \node[block, fill=blue!20] (ctrl) {Control Unit};
    \node[block, fill=green!20, below left=of ctrl] (rft) {RFT Engine};
    \node[block, fill=green!20, below=of ctrl] (quant) {Quantum Sim};
    \node[block, fill=green!20, below right=of ctrl] (wave) {Wave Logic};
    \node[block, fill=yellow!20, below=of quant] (mem) {Shared Memory};
    \node[block, fill=red!20, below=of mem] (noc) {NoC Interface};
    
    \draw[arrow] (ctrl) -- (rft);
    \draw[arrow] (ctrl) -- (quant);
    \draw[arrow] (ctrl) -- (wave);
    \draw[arrow] (rft) -- (mem);
    \draw[arrow] (quant) -- (mem);
    \draw[arrow] (wave) -- (mem);
    \draw[arrow] (mem) -- (noc);
\end{tikzpicture}
\end{center}

\section{Kernel Modes (from fpga\_top.json)}
\begin{table}[h]
\centering
\small
\begin{tabular}{@{}clll@{}}\toprule
Mode & Name & Function & Status \\ \midrule
0 & \texttt{GOLDEN\_RFT} & Forward/inverse RFT & Verified \\
1 & \texttt{FAST\_RFT} & NUFFT-accelerated RFT & Experimental \\
2 & \texttt{GRAM\_CORRECT} & Löwdin orthogonalization & Experimental \\
3 & \texttt{WAVE\_XOR} & Bitwise XOR in wave domain & Experimental \\
4 & \texttt{WAVE\_AND} & Bitwise AND in wave domain & Experimental \\
5 & \texttt{WAVE\_ARITH} & Wave arithmetic & Experimental \\
6 & \texttt{H3\_CASCADE} & Hybrid compression pipeline & Verified \\
7 & \texttt{SIS\_HASH} & Lattice-style hash & Experimental \\
8 & \texttt{FEISTEL\_48} & 48-round Feistel cipher & Experimental \\
9 & \texttt{GROVER\_SIM} & Grover search simulation & Experimental \\
10 & \texttt{DENOISE\_ECG} & ECG denoising kernel & Experimental \\
11 & \texttt{DENOISE\_EEG} & EEG denoising kernel & Experimental \\
12 & \texttt{CHIRP\_DETECT} & Chirp signal detection & Verified \\
13 & \texttt{VARIANT\_AUTO} & Auto-select RFT variant & Experimental \\
14 & \texttt{BENCHMARK} & Performance benchmark mode & Verified \\
15 & \texttt{IDLE} & Low-power idle state & Verified \\ \bottomrule
\end{tabular}
\caption{RFTPU kernel modes. "Verified" means testbench passes; "Experimental" means work-in-progress.}
\end{table}

\section{Running the Simulation}
\begin{lstlisting}[language=bash, caption={RFTPU Simulation Commands}]
# Functional simulation with Icarus Verilog
cd hardware
iverilog -o fpga_sim fpga_top.sv tb/fpga_top_tb.v
vvp fpga_sim

# View waveforms
gtkwave quantoniumos_sim.vcd

# OpenLane synthesis (if installed)
cd openlane
flow.tcl -design rftpu -tag run1
\end{lstlisting}

\section{Resource Estimates}
\begin{table}[h]
\centering
\begin{tabular}{@{}lrr@{}}\toprule
Resource & Estimate & Notes \\ \midrule
LUTs (Xilinx Artix-7) & $\sim$15,000 & Mode 0 only \\
DSP Slices & 48 & Complex multiply \\
Block RAM & 32 (36Kb each) & Coefficient storage \\
Max Frequency & $\sim$100 MHz & Post-synthesis est. \\
Power & $\sim$500 mW & Active mode est. \\ \bottomrule
\end{tabular}
\caption{Rough FPGA resource estimates (varies by toolchain and optimization).}
\end{table}

\chapter{Medical Denoising (ECG/EEG)}

\begin{todobox}{12}
\begin{itemize}
    \item[$\square$] Describe why RFT preserves morphology (quasi-periodic beats).
    \item[$\square$] Run \texttt{rft\_medical\_benchmark\_v2.py}.
    \item[$\square$] Compare PSNR vs baseline wavelet-only.
\end{itemize}
\end{todobox}

\section{Why These Signals Fit the Model}
ECG and EEG are not perfectly periodic, but they often exhibit strong quasi-periodic structure (ECG beats, rhythmic EEG bands) plus nonstationary noise (motion artifacts, baseline wander, electrode noise).

\section{Hybrid Denoising View}
A useful conceptual split:
\begin{itemize}
    \item \textbf{Wavelets}: handle localized transients and baseline drift.
    \item \textbf{RFT components}: capture quasi-periodic morphology and repeating microstructure that may not align with integer Fourier grids.
\end{itemize}
The practical denoiser is typically a sequence of transforms and thresholding rules rather than a single transform.

\section{Benchmark Script}
The repository provides a benchmark script intended to reproduce and compare denoising performance:
\begin{verbatim}
python benchmarks/rft_medical_benchmark_v2.py
\end{verbatim}
When reporting, include dataset source (and any preprocessing), PSNR or SNR improvement, and morphology-sensitive checks (e.g., preservation of QRS complexes).

\begin{warningbox}
Medical results in this repository are research artifacts. They are not a medical device and must not be used for clinical decision-making.
\end{warningbox}

\section{ECG Denoising Pipeline}
\begin{enumerate}
    \item \textbf{Baseline wander removal}: High-pass filter or wavelet baseline subtraction.
    \item \textbf{RFT decomposition}: Transform signal to RFT domain.
    \item \textbf{Thresholding}: Soft or hard thresholding of small coefficients.
    \item \textbf{Inverse RFT}: Reconstruct denoised signal.
    \item \textbf{QRS preservation check}: Verify R-peak amplitudes are maintained.
\end{enumerate}

\begin{lstlisting}[language=Python, caption={ECG Denoising Example}]
import numpy as np
from algorithms.rft.medical.ecg_denoiser import ECGDenoiser

# Simulate noisy ECG (in practice, load from PhysioNet)
fs = 360  # sampling rate
t = np.arange(0, 10, 1/fs)
clean_ecg = np.sin(2 * np.pi * 1.0 * t)  # simplified heartbeat
noise = 0.3 * np.random.randn(len(t))
noisy_ecg = clean_ecg + noise

denoiser = ECGDenoiser(
    rft_variant='harmonic_phase',
    threshold_method='soft',
    threshold_level=0.1
)

denoised = denoiser.denoise(noisy_ecg, fs=fs)

# Compute SNR improvement
snr_before = 10 * np.log10(np.var(clean_ecg) / np.var(noise))
residual_noise = denoised - clean_ecg
snr_after = 10 * np.log10(np.var(clean_ecg) / np.var(residual_noise))
print(f"SNR improvement: {snr_after - snr_before:.2f} dB")
\end{lstlisting}

\section{EEG Band Separation}
EEG signals contain distinct frequency bands:
\begin{itemize}
    \item \textbf{Delta} (0.5--4 Hz): Deep sleep
    \item \textbf{Theta} (4--8 Hz): Drowsiness, meditation
    \item \textbf{Alpha} (8--13 Hz): Relaxed wakefulness
    \item \textbf{Beta} (13--30 Hz): Active thinking
    \item \textbf{Gamma} (30--100 Hz): Cognitive processing
\end{itemize}

RFT can separate these bands while preserving transient events (spikes, K-complexes) that may not align with integer Fourier grids.

\section{Morphology Preservation Metrics}
Beyond PSNR/SNR, evaluate denoising quality with:
\begin{itemize}
    \item \textbf{R-peak correlation}: Correlation between original and denoised R-peak locations.
    \item \textbf{QRS width preservation}: Ratio of QRS complex duration before/after.
    \item \textbf{ST segment distortion}: Mean squared error in the ST segment.
    \item \textbf{Clinical annotation agreement}: If available, compare with cardiologist labels.
\end{itemize}

\section{Dataset Sources}
\begin{itemize}
    \item \textbf{MIT-BIH Arrhythmia Database}: Classic ECG dataset with annotations.
    \item \textbf{PhysioNet Challenge datasets}: Various cardiac and neurological signals.
    \item \textbf{Sleep-EDF}: EEG recordings for sleep stage analysis.
\end{itemize}

The repository includes fetch scripts in \texttt{data/} to download these datasets.

\section{Exercises}
\begin{enumerate}
    \item Download the MIT-BIH dataset and run the medical benchmark.
    \item Compare RFT denoising against wavelet-only denoising for Record 100.
    \item Plot the power spectrum before and after denoising. Which frequencies are attenuated?
    \item Implement a simple R-peak detector and measure detection accuracy before/after denoising.
\end{enumerate}

% APPENDIX ---------------------------------------------------------------
\appendix
\chapter{API Quick Reference}

This appendix provides a comprehensive reference for the main QuantoniumOS APIs.

\section{Core RFT Module}
\begin{lstlisting}[language=Python, caption={RFT Core API}]
from algorithms.rft.core.canonical_true_rft import CanonicalTrueRFT

# Initialize with size (power of 2 recommended for FFT-based variants)
rft = CanonicalTrueRFT(size=1024)

# Forward transform: time domain -> RFT domain
Y = rft.forward_transform(x)

# Inverse transform: RFT domain -> time domain
x_hat = rft.inverse_transform(Y)

# Get the basis matrix (for analysis)
Phi = rft.get_basis_matrix()

# Compute Gram matrix (should be close to identity if well-conditioned)
G = Phi.conj().T @ Phi
\end{lstlisting}

\section{RFT Variants}
\begin{lstlisting}[language=Python, caption={RFT Variant Selection}]
from algorithms.rft import (
    GoldenRFT,           # Classic golden-ratio spacing
    FastRFT,             # NUFFT-accelerated
    HarmonicPhaseRFT,    # Phase-optimized for harmonic signals
    EntropyModRFT,       # Entropy-adaptive modulation
    MultiscaleRFT,       # Multi-resolution analysis
    ChirpRFT             # Chirp-optimized basis
)

# Each variant shares the same interface
rft = GoldenRFT(size=1024)
Y = rft.forward_transform(x)

# Auto-selection based on signal characteristics
from algorithms.rft.utils.variant_selector import auto_select_variant
variant, rationale = auto_select_variant(signal, fs=44100)
\end{lstlisting}

\section{Symbolic Wave Computer}
\begin{lstlisting}[language=Python, caption={Wave Computer API}]
from algorithms.rft.core.symbolic_wave_computer import SymbolicWaveComputer

# Initialize with bit width
swc = SymbolicWaveComputer(num_bits=8)

# Encode integer to wave representation
wave = swc.encode(0b10101010)

# Decode wave back to integer
value = swc.decode(wave)

# Wave-domain operations
wave_a = swc.encode(42)
wave_b = swc.encode(17)

wave_xor = swc.wave_xor(wave_a, wave_b)
wave_and = swc.wave_and(wave_a, wave_b)
wave_add = swc.wave_add(wave_a, wave_b)

# Verify results
assert swc.decode(wave_xor) == (42 ^ 17)
assert swc.decode(wave_and) == (42 & 17)
assert swc.decode(wave_add) == (42 + 17)
\end{lstlisting}

\section{Quantum Simulation}
\begin{lstlisting}[language=Python, caption={Quantum Simulation API}]
from algorithms.rft.quantum.quantum_search import QuantumSearch
from algorithms.rft.quantum.quantum_state import QuantumState
from algorithms.rft.quantum.quantum_gates import H, X, Y, Z, CNOT, RZ

# Create quantum state
n_qubits = 4
state = QuantumState(n_qubits)  # Initialized to |0000>

# Apply gates
state = H(state, qubit=0)       # Hadamard on qubit 0
state = CNOT(state, control=0, target=1)  # CNOT
state = RZ(state, qubit=2, angle=np.pi/4)  # Rotation

# Measure
result, collapsed_state = state.measure()

# Grover search
qs = QuantumSearch(n_qubits=4)
marked_items = [5, 10]
result = qs.search(marked_items, iterations='optimal')
\end{lstlisting}

\section{Compression Pipeline}
\begin{lstlisting}[language=Python, caption={H3 Compression API}]
from algorithms.rft.compression.h3_cascade import H3Cascade

h3 = H3Cascade(
    wavelet='db4',
    structure_transform='dct',
    texture_transform='golden_rft',
    quantization_bits=8
)

# Compress
compressed = h3.encode(image)
print(f"Size: {len(compressed.data)} bytes")

# Decompress
reconstructed = h3.decode(compressed)

# Get compression statistics
stats = h3.get_stats()
print(f"Structure energy: {stats['structure_energy']:.2f}")
print(f"Texture energy: {stats['texture_energy']:.2f}")
\end{lstlisting}

\section{Medical Denoising}
\begin{lstlisting}[language=Python, caption={Medical Denoising API}]
from algorithms.rft.medical.ecg_denoiser import ECGDenoiser
from algorithms.rft.medical.eeg_denoiser import EEGDenoiser

# ECG denoising
ecg_denoiser = ECGDenoiser(
    rft_variant='harmonic_phase',
    threshold_method='soft',
    preserve_qrs=True
)
clean_ecg = ecg_denoiser.denoise(noisy_ecg, fs=360)

# EEG band separation
eeg_denoiser = EEGDenoiser(bands=['alpha', 'beta', 'gamma'])
bands = eeg_denoiser.separate_bands(eeg_signal, fs=256)
clean_eeg = eeg_denoiser.denoise(noisy_eeg, fs=256)
\end{lstlisting}

\section{Crypto (Research Only)}
\begin{lstlisting}[language=Python, caption={Experimental Crypto API}]
from algorithms.rft.crypto.enhanced_rft_crypto_v2 import EnhancedRFTCryptoV2
from algorithms.rft.crypto.sis_rft_hash import SISRFTHash

# EXPERIMENTAL - NOT FOR PRODUCTION USE
cipher = EnhancedRFTCryptoV2(key=b'sixteen_byte_key')
ciphertext = cipher.encrypt(plaintext)
decrypted = cipher.decrypt(ciphertext)

# Hash function (research)
hasher = SISRFTHash(output_bits=256)
digest = hasher.hash(message)
\end{lstlisting}

\chapter{Mathematical Foundations}

This appendix provides deeper mathematical background for readers seeking rigorous foundations.

\section{Frame Theory Essentials}
\begin{definition}[Frame]
A sequence $\{\phi_k\}_{k=1}^M$ in a Hilbert space $\mathcal{H}$ is a \textbf{frame} if there exist constants $0 < A \leq B < \infty$ (frame bounds) such that for all $x \in \mathcal{H}$:
\begin{equation}
A\|x\|^2 \leq \sum_{k=1}^M |\langle x, \phi_k \rangle|^2 \leq B\|x\|^2
\end{equation}
\end{definition}

\begin{itemize}
    \item If $A = B$, the frame is \textbf{tight} (behaves like an orthonormal basis up to scaling).
    \item If $A = B = 1$, the frame is a \textbf{Parseval frame} (exact isometry).
    \item The \textbf{frame operator} is $S = \Phi\Phi^\dagger$, where $\Phi$ is the analysis matrix.
    \item The \textbf{canonical dual frame} is $\tilde{\phi}_k = S^{-1}\phi_k$.
\end{itemize}

\section{Golden Ratio Properties}
The golden ratio $\phi = \frac{1+\sqrt{5}}{2} \approx 1.618$ has unique properties:
\begin{enumerate}
    \item \textbf{Continued fraction}: $\phi = 1 + \cfrac{1}{1 + \cfrac{1}{1 + \cfrac{1}{\ddots}}}$ (slowest convergent).
    \item \textbf{Algebraic}: $\phi^2 = \phi + 1$, so $\phi^n = F_n\phi + F_{n-1}$ where $F_n$ is Fibonacci.
    \item \textbf{Irrationality measure}: $\phi$ is the "most irrational" number in the sense of Diophantine approximation.
    \item \textbf{Low discrepancy}: Points $\{n\phi \mod 1\}$ are maximally spread (Weyl's theorem).
\end{enumerate}

\begin{theorem}[Three-Distance Theorem]
For any irrational $\alpha$ and integer $N$, the points $\{k\alpha \mod 1\}_{k=1}^N$ partition $[0,1)$ into gaps of at most three distinct lengths.
\end{theorem}

For $\alpha = \phi^{-1}$, these gaps follow the Fibonacci pattern, which is exploited in RFT frequency placement.

\section{Condition Number Analysis}
The condition number $\kappa(\Phi) = \sigma_{\max}/\sigma_{\min}$ measures numerical stability:
\begin{itemize}
    \item $\kappa = 1$: Perfectly conditioned (orthonormal)
    \item $\kappa < 10$: Well-conditioned for most applications
    \item $\kappa > 100$: May require Gram correction or regularization
    \item $\kappa = \infty$: Singular (rank-deficient)
\end{itemize}

\begin{lstlisting}[language=Python, caption={Condition Number Computation}]
import numpy as np

def analyze_basis_conditioning(Phi):
    """Analyze numerical properties of a basis matrix."""
    G = Phi.conj().T @ Phi  # Gram matrix
    eigenvalues = np.linalg.eigvalsh(G)
    
    cond_number = np.sqrt(eigenvalues.max() / eigenvalues.min())
    frame_bounds = (eigenvalues.min(), eigenvalues.max())
    
    return {
        'condition_number': cond_number,
        'frame_bounds': frame_bounds,
        'is_tight': np.allclose(eigenvalues.min(), eigenvalues.max()),
        'coherence': np.max(np.abs(G - np.diag(np.diag(G))))
    }
\end{lstlisting}

\section{Quantum Mechanics Primer}
\begin{definition}[Qubit]
A qubit is a two-level quantum system described by
\begin{equation}
|\psi\rangle = \alpha|0\rangle + \beta|1\rangle, \quad |\alpha|^2 + |\beta|^2 = 1
\end{equation}
where $\alpha, \beta \in \mathbb{C}$ are probability amplitudes.
\end{definition}

\begin{theorem}[No-Cloning]
There is no unitary operation $U$ such that $U(|\psi\rangle \otimes |0\rangle) = |\psi\rangle \otimes |\psi\rangle$ for all $|\psi\rangle$.
\end{theorem}

\begin{theorem}[Solovay-Kitaev]
Any single-qubit unitary can be approximated to precision $\epsilon$ using $O(\log^c(1/\epsilon))$ gates from a universal gate set, where $c \approx 2$.
\end{theorem}

\chapter{Troubleshooting Guide}

\section{Common Installation Issues}
\begin{description}
    \item[NumPy version mismatch] Ensure NumPy $\geq 1.21$. Run \texttt{pip install --upgrade numpy}.
    \item[BLAS not found] Install OpenBLAS: \texttt{apt install libopenblas-dev} (Linux) or use conda.
    \item[Memory errors] Reduce \texttt{size} parameter or use \texttt{FastRFT} for large signals.
\end{description}

\section{Runtime Warnings}
\begin{description}
    \item[Gram correction warning] Basis conditioning is poor. Apply \texttt{gram\_correct()} or use smaller size.
    \item[Numerical overflow] Scale input signal to $[-1, 1]$ range before transformation.
    \item[Slow convergence] Increase iteration limit or switch to a faster variant.
\end{description}

\section{Benchmark Reproducibility}
\begin{enumerate}
    \item Record Python version, NumPy/SciPy versions, and BLAS backend.
    \item Set random seeds: \texttt{np.random.seed(42)}.
    \item Run on a quiet machine (no background load).
    \item Report median of 5+ runs with min/max range.
    \item Note CPU model and available memory.
\end{enumerate}

\section{Hardware Simulation Issues}
\begin{description}
    \item[Icarus Verilog errors] Ensure SystemVerilog support: \texttt{iverilog -g2012}.
    \item[Missing VCD file] Check simulation ran to completion; look for assertion failures.
    \item[OpenLane flow failures] Verify PDK is installed and \texttt{PDK\_ROOT} is set.
\end{description}

\chapter{Glossary}
\begin{description}
    \item[Amplitude] The magnitude of a complex coefficient; determines probability in quantum mechanics.
    \item[ANS] Asymmetric Numeral Systems; modern entropy coding method used in compression.
    \item[ARFT] Adaptive Resonant Fourier Transform; variant with signal-dependent parameters.
    \item[Avalanche Effect] Cryptographic property where small input changes cause large output changes.
    \item[Basis] A set of vectors that span a space; can be orthonormal, biorthogonal, or overcomplete.
    \item[BPP] Bits Per Pixel; compression metric measuring average bits per image pixel.
    \item[BPSK] Binary Phase-Shift Keying; maps bits to $\pm1$ symbols in communication.
    \item[Chirp] Signal with time-varying frequency; common in radar and biomedical signals.
    \item[Coherence] Maximum inner product between distinct basis vectors; lower is better for CS.
    \item[Condition Number] Ratio $\sigma_{\max}/\sigma_{\min}$; measures numerical stability.
    \item[DCT] Discrete Cosine Transform; real-valued transform used in JPEG and video codecs.
    \item[DFT] Discrete Fourier Transform; complex exponential basis on integer frequencies.
    \item[Diffusion] In crypto, spreading influence of input bits across output; in DSP, signal spreading.
    \item[Entanglement] Quantum correlation between particles that cannot be described classically.
    \item[Feistel] Network structure for block ciphers; splits block into halves for iterative mixing.
    \item[FFT] Fast Fourier Transform; $O(N\log N)$ algorithm for DFT computation.
    \item[Frame] Overcomplete spanning set with bounded analysis/synthesis; generalizes basis.
    \item[Frame Bounds] Constants $A, B$ in frame inequality; ratio $B/A$ indicates redundancy.
    \item[Golden Ratio] $\phi = (1+\sqrt{5})/2 \approx 1.618$; appears in RFT frequency spacing.
    \item[Gram Matrix] $G=\Phi^\dagger\Phi$; measures basis inner products; identity for orthonormal.
    \item[Grover] Quantum search algorithm; finds marked item in $O(\sqrt{N})$ queries.
    \item[H3] Hybrid compression cascade: structure (DCT) + texture (RFT) + entropy coding.
    \item[Hadamard] Quantum gate creating superposition: $H|0\rangle = (|0\rangle+|1\rangle)/\sqrt{2}$.
    \item[Lattice] Discrete additive subgroup of $\mathbb{R}^n$; basis of post-quantum crypto.
    \item[Löwdin] Symmetric orthogonalization $\tilde{\Phi}=\Phi G^{-1/2}$; preserves structure.
    \item[NUFFT] Non-Uniform FFT; computes DFT at arbitrary frequencies in $O(N\log N)$.
    \item[Oracle] Black-box function in algorithm analysis; Grover requires quantum oracle.
    \item[Parseval] Frame with $A=B=1$; isometric (energy-preserving) analysis.
    \item[Phase] Argument of a complex number; carries timing/frequency information.
    \item[PSNR] Peak Signal-to-Noise Ratio; $10\log_{10}(\text{peak}^2/\text{MSE})$ in dB.
    \item[Qubit] $\alpha|0\rangle+\beta|1\rangle$, $|\alpha|^2+|\beta|^2=1$; quantum bit.
    \item[QRS Complex] The main spike in ECG; corresponds to ventricular depolarization.
    \item[RFT] Resonant Fourier Transform; uses golden-ratio or quasi-periodic frequency spacing.
    \item[RFTPU] Resonant Fourier Transform Processing Unit; hardware accelerator study.
    \item[S-box] Substitution box; nonlinear lookup table in block ciphers.
    \item[SIS] Short Integer Solution lattice problem; hardness assumption for PQ crypto.
    \item[SNR] Signal-to-Noise Ratio; $10\log_{10}(\text{signal power}/\text{noise power})$ in dB.
    \item[Superposition] Quantum state as linear combination of basis states.
    \item[Tight Frame] Frame with equal bounds $A=B$; reconstruction by simple rescaling.
    \item[Unitary] Matrix with $U^\dagger U = I$; preserves inner products and energy.
    \item[VCD] Value Change Dump; waveform file format for digital simulation.
    \item[Wavelet] Localized oscillating function; provides time-frequency analysis.
\end{description}

\backmatter
\chapter*{Bibliography}
\addcontentsline{toc}{chapter}{Bibliography}

\section*{Signal Processing and Transforms}
\begin{enumerate}
    \item Oppenheim, A. V., Schafer, R. W. \textit{Discrete-Time Signal Processing}. Pearson, 3rd ed., 2009.
    \item Mallat, S. \textit{A Wavelet Tour of Signal Processing}. Academic Press, 3rd ed., 2008.
    \item Daubechies, I. \textit{Ten Lectures on Wavelets}. SIAM, 1992.
    \item Dutt, A., Rokhlin, V. "Fast Fourier Transforms for Nonequispaced Data." \textit{SIAM J. Sci. Comput.}, 1993.
\end{enumerate}

\section*{Frame Theory}
\begin{enumerate}[resume]
    \item Christensen, O. \textit{An Introduction to Frames and Riesz Bases}. Birkhäuser, 2nd ed., 2016.
    \item Casazza, P. G., Kutyniok, G. \textit{Finite Frames: Theory and Applications}. Birkhäuser, 2013.
    \item Benedetto, J. J., Fickus, M. "Finite Normalized Tight Frames." \textit{Adv. Comput. Math.}, 2003.
\end{enumerate}

\section*{Number Theory and Golden Ratio}
\begin{enumerate}[resume]
    \item Schroeder, M. R. \textit{Number Theory in Science and Communication}. Springer, 5th ed., 2009.
    \item Livio, M. \textit{The Golden Ratio: The Story of Phi}. Broadway Books, 2002.
    \item Weyl, H. "Über die Gleichverteilung von Zahlen mod. Eins." \textit{Math. Ann.}, 1916.
\end{enumerate}

\section*{Quantum Computing}
\begin{enumerate}[resume]
    \item Nielsen, M. A., Chuang, I. L. \textit{Quantum Computation and Quantum Information}. Cambridge, 10th anniv. ed., 2010.
    \item Grover, L. K. "A Fast Quantum Mechanical Algorithm for Database Search." \textit{STOC}, 1996.
    \item Shor, P. W. "Algorithms for Quantum Computation." \textit{FOCS}, 1994.
    \item Preskill, J. "Quantum Computing in the NISQ Era and Beyond." \textit{Quantum}, 2018.
\end{enumerate}

\section*{Cryptography}
\begin{enumerate}[resume]
    \item Micciancio, D., Regev, O. "Lattice-based Cryptography." In \textit{Post-Quantum Cryptography}, Springer, 2009.
    \item Ajtai, M. "Generating Hard Instances of Lattice Problems." \textit{STOC}, 1996.
    \item Peikert, C. "A Decade of Lattice Cryptography." \textit{Found. Trends Theor. Comput. Sci.}, 2016.
\end{enumerate}

\section*{Compression and Coding}
\begin{enumerate}[resume]
    \item Sayood, K. \textit{Introduction to Data Compression}. Morgan Kaufmann, 5th ed., 2017.
    \item Wallace, G. K. "The JPEG Still Picture Compression Standard." \textit{IEEE Trans. Consumer Electron.}, 1992.
    \item Duda, J. "Asymmetric Numeral Systems." arXiv:0902.0271, 2009.
\end{enumerate}

\section*{Medical Signal Processing}
\begin{enumerate}[resume]
    \item Sörnmo, L., Laguna, P. \textit{Bioelectrical Signal Processing in Cardiac and Neurological Applications}. Academic Press, 2005.
    \item Goldberger, A. L., et al. "PhysioBank, PhysioToolkit, and PhysioNet." \textit{Circulation}, 2000.
    \item Pan, J., Tompkins, W. J. "A Real-Time QRS Detection Algorithm." \textit{IEEE Trans. Biomed. Eng.}, 1985.
\end{enumerate}

\section*{Hardware and FPGA}
\begin{enumerate}[resume]
    \item Harris, D. M., Harris, S. L. \textit{Digital Design and Computer Architecture}. Morgan Kaufmann, 2nd ed., 2012.
    \item Cong, J., et al. "High-Level Synthesis for FPGAs." \textit{IEEE Design \& Test}, 2011.
    \item Shalan, M., Edwards, T. "Building OpenLane: A 130nm OpenROAD-based Tapeout." \textit{WOSET}, 2020.
\end{enumerate}

\chapter*{Index}
\addcontentsline{toc}{chapter}{Index}
\small
\begin{multicols}{2}
\noindent
Amplitude amplification, 58 \\
ANS (entropy coding), 72 \\
ARFT (adaptive RFT), 34 \\
Avalanche effect, 85 \\
\\
Basis matrix, 18 \\
Bell state, 48 \\
BPP (bits per pixel), 73 \\
BPSK encoding, 39 \\
\\
Chirp detection, 36 \\
CNOT gate, 50 \\
Condition number, 28 \\
Cryptography (PQ), 80--88 \\
\\
DCT (discrete cosine), 71 \\
Denoising (ECG/EEG), 90--98 \\
Diffusion layer, 83 \\
\\
ECG pipeline, 92 \\
EEG bands, 94 \\
Entanglement, 48 \\
\\
Feistel network, 82 \\
FFT acceleration, 32 \\
Frame bounds, 22 \\
Frame theory, 20--24 \\
\\
Golden ratio ($\phi$), 16, 102 \\
Gram correction, 26--30 \\
Gram matrix, 25 \\
Grover's algorithm, 52--60 \\
\\
H3 cascade, 68--76 \\
Hadamard gate, 46 \\
Hardware (RFTPU), 100--112 \\
\\
Inverse transform, 19 \\
\\
Kernel modes, 106 \\
\\
Lattice problems, 81 \\
Löwdin orthogonalization, 27 \\
\\
Medical benchmarks, 96 \\
MIT-BIH database, 95 \\
Morphology preservation, 94 \\
\\
NUFFT, 32 \\
\\
Oracle (quantum), 54 \\
Orthogonalization, 27 \\
\\
Parseval frame, 23 \\
Phase encoding, 38 \\
PhysioNet, 95 \\
Post-quantum crypto, 80 \\
PSNR metric, 73 \\
\\
QRS complex, 93 \\
Quantum gates, 46--50 \\
Quantum search, 52--60 \\
Quantum state, 44 \\
Qubit, 44 \\
\\
Rate-distortion, 74 \\
RFT definition, 14 \\
RFT variants, 34--36 \\
RFTPU architecture, 104 \\
Ripple-carry adder, 42 \\
\\
S-box (nonlinear), 82 \\
Signal classes, 17 \\
SIS problem, 81 \\
Superposition, 45 \\
\\
Texture compression, 70 \\
Three-distance theorem, 103 \\
Tight frame, 23 \\
\\
Unitarity, 26 \\
\\
VCD waveforms, 108 \\
\\
Wave-domain logic, 38--42 \\
Wave XOR, 40 \\
Wavelet split, 69 \\
\end{multicols}

\end{document}
