#!/usr/bin/env python3
"""
RFT-Wavelet Hybrid v2 for Medical Image Denoising
==================================================

Optimized version with:
1. Anscombe transform for Poisson noise (variance-stabilizing)
2. Fast separable RFT (vectorized, no Python loops)
3. Multi-level RFT filtering (all wavelet levels)

Performance target: <20ms for 256×256 images (10× speedup)

Copyright (C) 2025 Luis M. Minier / quantoniumos
Licensed under AGPL-3.0-or-later
"""

import numpy as np
from typing import Tuple, Optional
from functools import lru_cache


# =============================================================================
# Anscombe Transform for Poisson Noise
# =============================================================================

def anscombe_transform(image: np.ndarray) -> np.ndarray:
    """
    Anscombe variance-stabilizing transform for Poisson noise.
    
    Transforms Poisson-distributed data to approximately Gaussian with σ≈1.
    f(x) = 2 * sqrt(x + 3/8)
    """
    return 2.0 * np.sqrt(np.maximum(image, 0) + 3.0/8.0)


def inverse_anscombe(transformed: np.ndarray) -> np.ndarray:
    """
    Inverse Anscombe transform (exact unbiased inverse).
    
    Uses the algebraic inverse: x = (y/2)² - 3/8
    For better accuracy with low counts, use the exact unbiased inverse.
    """
    # Algebraic inverse
    return np.maximum((transformed / 2.0) ** 2 - 3.0/8.0, 0)


def inverse_anscombe_exact(transformed: np.ndarray) -> np.ndarray:
    """
    Exact unbiased inverse Anscombe transform.
    
    Accounts for bias in the transformation for more accurate reconstruction.
    Reference: Makitalo & Foi (2011)
    """
    # Exact unbiased inverse (asymptotic approximation)
    y = transformed
    return np.maximum(
        (y/2.0)**2 + 0.25 * np.sqrt(1.5) * y**(-1) - 11.0/8.0 * y**(-2) + 
        5.0/8.0 * np.sqrt(1.5) * y**(-3) - 1.0/8.0,
        0
    )


# =============================================================================
# Fast Separable RFT (Vectorized)
# =============================================================================

@lru_cache(maxsize=8)
def _get_rft_matrix(n: int) -> np.ndarray:
    """Get cached RFT transformation matrix for size n."""
    try:
        from algorithms.rft.kernels.resonant_fourier_transform import build_rft_kernel
        return build_rft_kernel(n)
    except ImportError:
        # Fallback: use DFT matrix
        k = np.arange(n)
        return np.exp(-2j * np.pi * np.outer(k, k) / n) / np.sqrt(n)


def fast_rft_2d(image: np.ndarray) -> np.ndarray:
    """
    Fast 2D RFT using matrix multiplication (vectorized).
    
    ~10× faster than row-by-row Python loops.
    """
    rows, cols = image.shape
    
    # Get transformation matrices
    U_rows = _get_rft_matrix(cols)
    U_cols = _get_rft_matrix(rows)
    
    # Apply: Y = U_cols @ X @ U_rows.T (separable 2D transform)
    return U_cols @ image.astype(np.complex128) @ U_rows.T


def fast_irft_2d(coeffs: np.ndarray) -> np.ndarray:
    """
    Fast inverse 2D RFT using matrix multiplication.
    """
    rows, cols = coeffs.shape
    
    # Get transformation matrices (conjugate transpose for inverse)
    U_rows = _get_rft_matrix(cols)
    U_cols = _get_rft_matrix(rows)
    
    # Apply inverse: X = U_cols.H @ Y @ U_rows.conj()
    return (U_cols.conj().T @ coeffs @ U_rows.conj()).real


def fast_rft_filter(subband: np.ndarray, noise_var: float, 
                    filter_type: str = "wiener") -> np.ndarray:
    """
    Fast RFT-domain filtering (vectorized).
    
    Args:
        subband: Input wavelet subband
        noise_var: Estimated noise variance
        filter_type: "wiener" or "soft" thresholding
        
    Returns:
        Filtered subband
    """
    # Forward 2D RFT
    coeffs = fast_rft_2d(subband)
    
    if filter_type == "wiener":
        # Wiener filter: H = |S|² / (|S|² + σ²)
        power = np.abs(coeffs) ** 2
        wiener = power / (power + noise_var + 1e-10)
        filtered = coeffs * wiener
    else:
        # Soft thresholding in RFT domain
        threshold = np.sqrt(2 * noise_var * np.log(subband.size))
        mag = np.abs(coeffs)
        filtered = coeffs * np.maximum(1 - threshold / (mag + 1e-10), 0)
    
    # Inverse 2D RFT
    return fast_irft_2d(filtered)


# =============================================================================
# Optimized Haar Wavelet (same as v1, kept for clarity)
# =============================================================================

def _haar_decompose_2d(image: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """Single-level 2D Haar wavelet decomposition."""
    rows, cols = image.shape
    
    if rows % 2 != 0:
        image = np.vstack([image, image[-1:, :]])
        rows += 1
    if cols % 2 != 0:
        image = np.hstack([image, image[:, -1:]])
        cols += 1
    
    # Vectorized horizontal pass
    h_low = (image[:, 0::2] + image[:, 1::2]) * (1.0 / np.sqrt(2))
    h_high = (image[:, 0::2] - image[:, 1::2]) * (1.0 / np.sqrt(2))
    
    # Vectorized vertical pass
    LL = (h_low[0::2, :] + h_low[1::2, :]) * (1.0 / np.sqrt(2))
    LH = (h_low[0::2, :] - h_low[1::2, :]) * (1.0 / np.sqrt(2))
    HL = (h_high[0::2, :] + h_high[1::2, :]) * (1.0 / np.sqrt(2))
    HH = (h_high[0::2, :] - h_high[1::2, :]) * (1.0 / np.sqrt(2))
    
    return LL, LH, HL, HH


def _haar_reconstruct_2d(LL: np.ndarray, LH: np.ndarray, 
                          HL: np.ndarray, HH: np.ndarray,
                          original_shape: Tuple[int, int]) -> np.ndarray:
    """Single-level 2D Haar wavelet reconstruction."""
    rows, cols = LL.shape[0] * 2, LL.shape[1] * 2
    sqrt2_inv = 1.0 / np.sqrt(2)
    
    # Inverse vertical
    h_low = np.zeros((rows, LL.shape[1]))
    h_low[0::2, :] = (LL + LH) * sqrt2_inv
    h_low[1::2, :] = (LL - LH) * sqrt2_inv
    
    h_high = np.zeros((rows, HL.shape[1]))
    h_high[0::2, :] = (HL + HH) * sqrt2_inv
    h_high[1::2, :] = (HL - HH) * sqrt2_inv
    
    # Inverse horizontal
    image = np.zeros((rows, cols))
    image[:, 0::2] = (h_low + h_high) * sqrt2_inv
    image[:, 1::2] = (h_low - h_high) * sqrt2_inv
    
    return image[:original_shape[0], :original_shape[1]]


# =============================================================================
# Main Denoising Functions
# =============================================================================

def rft_wavelet_denoise_v2(noisy_image: np.ndarray,
                            levels: int = 2,
                            noise_model: str = "rician",
                            rft_all_levels: bool = True,
                            edge_enhance: bool = False) -> np.ndarray:
    """
    RFT-Wavelet Hybrid v2 - Optimized for speed and Poisson noise.
    
    Improvements over v1:
    1. Anscombe transform for Poisson noise (proper variance stabilization)
    2. Fast vectorized RFT (matrix multiply instead of loops)
    3. RFT filtering at all wavelet levels (not just finest)
    
    Args:
        noisy_image: Noisy input image (2D, normalized to [0,1])
        levels: Number of wavelet decomposition levels
        noise_model: "rician", "poisson", or "gaussian"
        rft_all_levels: Apply RFT at all levels (True) or just finest (False)
        edge_enhance: Apply edge enhancement (slower)
        
    Returns:
        Denoised image
    """
    original_shape = noisy_image.shape
    working_image = noisy_image.copy()
    
    # === POISSON: Apply Anscombe variance-stabilizing transform ===
    if noise_model == "poisson":
        # Scale to reasonable count range for Anscombe
        scale_factor = 1000.0  # Assume max ~1000 counts
        working_image = anscombe_transform(working_image * scale_factor)
        # After Anscombe, noise is approximately Gaussian with σ≈1
        anscombe_applied = True
    else:
        anscombe_applied = False
    
    # Ensure image size is compatible with wavelet levels
    rows, cols = working_image.shape
    pad_rows = (2 ** levels - rows % (2 ** levels)) % (2 ** levels)
    pad_cols = (2 ** levels - cols % (2 ** levels)) % (2 ** levels)
    
    if pad_rows > 0 or pad_cols > 0:
        padded = np.pad(working_image, ((0, pad_rows), (0, pad_cols)), mode='reflect')
    else:
        padded = working_image
    
    # Multi-level wavelet decomposition
    coeffs_pyramid = []
    current = padded
    
    for level in range(levels):
        LL, LH, HL, HH = _haar_decompose_2d(current)
        coeffs_pyramid.append((LH, HL, HH, current.shape))
        current = LL
    
    processed_LL = current
    
    # Process each level (coarsest to finest)
    for level in range(levels - 1, -1, -1):
        LH, HL, HH, shape = coeffs_pyramid[level]
        
        # Estimate noise variance from HH subband
        noise_var = _estimate_noise_var_mad(HH)
        
        # Scale-dependent noise adjustment
        # Noise decreases at coarser scales (by factor of 2 per level)
        level_noise_var = noise_var * (2.0 ** (levels - 1 - level))
        
        # Model-specific threshold adjustment
        if noise_model == "rician":
            # Rician: slightly higher threshold due to signal-dependent noise
            threshold_mult = 1.2 + 0.1 * level  # More aggressive at coarse levels
        elif noise_model == "poisson":
            # After Anscombe, treat as Gaussian with σ≈1
            threshold_mult = 1.0
            level_noise_var = 1.0  # Anscombe stabilizes to σ≈1
        else:
            threshold_mult = 1.0
        
        # Apply RFT filtering at this level?
        use_rft = rft_all_levels or (level == 0)
        
        if use_rft and min(LH.shape) >= 8:  # RFT needs minimum size
            # Fast RFT Wiener filtering
            LH_filtered = fast_rft_filter(LH, level_noise_var, "wiener")
            HL_filtered = fast_rft_filter(HL, level_noise_var, "wiener")
            HH_filtered = fast_rft_filter(HH, level_noise_var * 2, "wiener")
        else:
            # Simple soft thresholding for small subbands
            threshold = threshold_mult * np.sqrt(2 * level_noise_var * np.log(LH.size + 1))
            LH_filtered = _soft_threshold(LH, threshold * 0.7)
            HL_filtered = _soft_threshold(HL, threshold * 0.7)
            HH_filtered = _soft_threshold(HH, threshold)
        
        # BayesShrink refinement
        signal_var = max(np.var(LH_filtered) - level_noise_var, 1e-10)
        bayes_threshold = threshold_mult * level_noise_var / np.sqrt(signal_var)
        
        LH_denoised = _soft_threshold(LH_filtered, bayes_threshold * 0.3)
        HL_denoised = _soft_threshold(HL_filtered, bayes_threshold * 0.3)
        HH_denoised = _soft_threshold(HH_filtered, bayes_threshold * 0.5)
        
        # Reconstruct this level
        processed_LL = _haar_reconstruct_2d(processed_LL, LH_denoised, 
                                             HL_denoised, HH_denoised, shape)
    
    # Trim to original size
    denoised = processed_LL[:original_shape[0], :original_shape[1]]
    
    # === POISSON: Inverse Anscombe transform ===
    if anscombe_applied:
        denoised = inverse_anscombe_exact(denoised) / scale_factor
    
    return np.clip(denoised, 0, 1)


def _estimate_noise_var_mad(subband: np.ndarray) -> float:
    """MAD-based noise variance estimation."""
    mad = np.median(np.abs(subband - np.median(subband)))
    return (mad / 0.6745) ** 2


def _soft_threshold(coeffs: np.ndarray, threshold: float) -> np.ndarray:
    """Soft thresholding."""
    return np.sign(coeffs) * np.maximum(np.abs(coeffs) - threshold, 0)


# =============================================================================
# Adaptive Version with Auto-Detection
# =============================================================================

def rft_wavelet_denoise_v2_adaptive(noisy_image: np.ndarray,
                                     reference: Optional[np.ndarray] = None) -> Tuple[np.ndarray, dict]:
    """
    Adaptive RFT-Wavelet v2 with automatic noise model detection.
    
    Auto-detects:
    - Noise model (Rician vs Poisson vs Gaussian)
    - Optimal number of decomposition levels
    - Whether multi-level RFT helps
    """
    import time
    start = time.perf_counter()
    
    # Estimate noise from HH subband
    LL, LH, HL, HH = _haar_decompose_2d(noisy_image)
    noise_sigma = np.median(np.abs(HH)) / 0.6745
    
    # Auto-select levels
    min_dim = min(noisy_image.shape)
    max_levels = max(1, int(np.log2(min_dim)) - 3)
    
    if noise_sigma > 0.12:
        levels = min(3, max_levels)
    elif noise_sigma > 0.06:
        levels = min(2, max_levels)
    else:
        levels = 1
    
    # Detect noise model from image statistics
    mean_val = np.mean(noisy_image)
    var_val = np.var(noisy_image)
    skewness = np.mean((noisy_image - mean_val) ** 3) / (np.std(noisy_image) ** 3 + 1e-10)
    
    # Poisson: variance ≈ mean, low skewness
    # Rician: positive skewness, especially at low SNR
    if 0.5 < var_val / (mean_val + 1e-10) < 2.0 and abs(skewness) < 0.3:
        noise_model = "poisson"
    elif skewness > 0.4:
        noise_model = "rician"
    else:
        noise_model = "gaussian"
    
    # Denoise
    denoised = rft_wavelet_denoise_v2(
        noisy_image, 
        levels=levels,
        noise_model=noise_model,
        rft_all_levels=True,
        edge_enhance=False
    )
    
    elapsed_ms = (time.perf_counter() - start) * 1000
    
    metrics = {
        "time_ms": elapsed_ms,
        "noise_sigma_est": noise_sigma,
        "levels": levels,
        "noise_model": noise_model,
        "version": "v2_optimized",
    }
    
    if reference is not None:
        mse_before = np.mean((noisy_image - reference) ** 2)
        mse_after = np.mean((denoised - reference) ** 2)
        metrics["psnr_before"] = 10 * np.log10(1.0 / (mse_before + 1e-10))
        metrics["psnr_after"] = 10 * np.log10(1.0 / (mse_after + 1e-10))
        metrics["psnr_improvement"] = metrics["psnr_after"] - metrics["psnr_before"]
    
    return denoised, metrics


# Convenience aliases
rft_wavelet_hybrid_v2 = rft_wavelet_denoise_v2
